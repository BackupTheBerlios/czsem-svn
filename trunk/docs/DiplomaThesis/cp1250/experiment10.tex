%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Experiment}
\label{sec:experiment}
Pùvodním zámìrem experimentu v~této práci bylo vyzkoušet nìkterou existující metodu automatické sémantické anotace. Pøi hledání vhodné metody jsme zjistili, e ve~vìtšinì projektù je algoritmická dokumentace pouitıch metod velmi struèná (alespoò dokumentace, která je veøejnì k dispozici). Získat nìjakı pouitelnı kód nebo knihovnu bylo problematické. Vıjimku tvoøí projekty KIM (popsanı v~sekci \ref{sec:KIM}) a GATE (sekce \ref{sec:GATE}). Avšak zamìøení tìchto dvou projektù pøíliš nevyhovovalo poadavkùm na~náš experiment.

Pøestavba architektury projektu KIM by byla pomìrnì nároèná a její vısledek nejistı. Pravdìpodobnì by vznikl pouze slabší \uv{bratr} bulharského KIM, kterı je podpoøen masivní databází informací v~pozadí. %která zde byla v~prùbìhu projektu KIM vytvoøena.

Projekt GATE je naproti KIM otevøenı a modulární. Jedná se o velmi obecnou softwarovou základnu pro lingvistickou anotaci a extrakci informací, která nabízí mnoho moností, k~dispozici je velké mnoství funkèních modulù. Ale k~èemu pøesnì bychom GATE chtìli pouít? Ponechali jsme tedy GATE jako otevøenou monost a zaèali pøesnìji hledat a specifikovat problém, kterı budeme øešit.

Paralelnì s~touto prací jsme mohli sledovat vıvoj prací Dušana Marušèáka a Roberta Novotného !!!citovat!!!. V~tìchto pracích se pokoušejí o~anotaci / extrakci informací ze~strukturovanıch web-stránek. Tento pøístup se èasto oznaèuje jako konstrukce \emph{wrapper-u}. Obì tyto práce se opírají o~zajímavı nápad vyuití opakujících se struktur uvnitø stránek. Vzniklé metody jsou pak témìø nezávislé na~konkrétní podobì vstupní stránky. Avšak pevná (HTML) struktura stránky podmiòuje pouití tìchto metod.

Zaèali jsme si uvìdomovat, mezeru v~oblasti extrakce informací z~pøirozeného textu v~Èeském jazyce. Nejsou nám známy vısledky ádné práce, která by se tímto tématem zabıvala. Pøitom èeská poèítaèová lingvistika je na~velmi vysoké úrovni.

Otevøela se nám monost spolupráce s~Martinem Labskım a Vojtìchem Svátekem na~èásti projektu The RAINBOW Project\footnote{http://rainbow.vse.cz/}. Konkrétnì bychom se zde zabıvali rozšíøením jejich systému pro extrakci informací pomocí \uv{extrakèní ontologie}. Jedná se o~propracovanı systém zaloenı na~široké paletì extrakèních pravidel, která jsou definovaná v~extrakèní ontologii. Jde však také pøedevším o konstrukci wrapper-u. Jedna z~moností naší spolupráce mìla spoèívat v~rozšíøení palety pravidel jejich projektu o~pravidla zaloená na~lingvistice.

K~ádné spolupráci zatím nedošlo, ale v~experimentu této práce se pokoušíme otestovat dostupné nástroje pro~lingvistickou anotaci èeskıch textù a prozkoumat monosti jejich vyuití pro~extrakci informací a automatickou sémantickou anotaci.

%Jmenovitì se jednalo o tyto nástroje: !!!!!!!!!!!!!doplnit!!!!!!!!!!!!!!!!. Byly

%!!!!!!!Pzor následující odstavec jsem okopíroval i do kapitoly pøínosy - vyøešit

%Postup experimentu se v jednotlivıch fázích snaí kopírovat skuteèné akce, které by bylo nutné provést v opravdovém projektu zamìøeném na sémantickou anotaci. V práci tak vzniká jednoduchá základní analıza tohoto typu projektù. Ve skuteèném projektu pak bude moné ji pøinejmenším jako inspiraci vyuít.


\section{Osnova prací}
\label{sec:osnaova_praci}
Postupem prací v~experimentu se snaíme simulovat postup opravdového projektu, kterı by byl zamìøenı na dodateènou automatickou sémantickou anotaci nìkterıch zdrojù webu. Tedy jsme v~situaci, kdy chceme nìjakım zpùsobem vyuít data na webu publikovaná. Abychom mohli tato data pouít, potøebujeme je získat v~takové formì, aby se dala strojovì zpracovávat a vyhodnocovat. Na webu jsou však tato data publikována tak, aby si je mohli prohlíet obyèejní lidští návštìvníci, nemají strukturu, kterou poadujeme.

Data která nás zajímají\footnote{Podrobnìjší diskuse o~vstupních datech experimentu je v~oddíle \ref{sec:data_in}.} mohou bıt vyjádøena pøirozenım jazykem v~textech èlánkù nìkolika webovıch portálù. V~našem experimentu se jedná o~èlánky hasièského zpravodajství z~èeskıch regionù na portálu MVÈR (podrobnìji v~oddíle \ref{sec:data_in}). Abychom se od tìchto èlánkù dostali k~datùm, která potøebujeme, budeme postupovat podle následující osnovy, která je graficky znázornìna na~obrázku \ref{pict:AP_schema1}.

\begin{figure}[!thb]
\begin{center}
\includegraphics[width=7cm, height=9cm]{../AP_schema1.eps}
\caption{Schéma aplikace } \label{pict:AP_schema1}
\end{center}
\end{figure}


\subsection{Pøíprava vstupních dat}
\label{sec:phase_data_prepare}
První, co musíme udìlat, je stáhnout poadované èlánky z~internetu k~dalšímu zpracování. Programy, které se zabıvají touto èinností nazıváme \emph{web crawler}. V~našem experimentu jsme naprogramovali velmi jednoduchı web crawler, kterı vyuívá kanál RSS\footnote{RSS -- RDF Site Summary bıvá oznaèováno \cite{SemWeb_Matulik} jako technologie sémantického webu.} publikovanı na~portálu MVÈR a stáhne všechny web-stránky s~èlánky, které nás zajímají.

Nyní potøebujeme ze~staenıch èlánkù extrahovat text, kterı budeme analyzovat. V~pøípadì hasièskıch èlánkù to nebyl velkı problém. Staèil jednoduchı skript, kterı pomocí nìkolika regulárních vırazù oddìlil text èlánku od HTML struktury web-stránky. Pøi našem druhém pokusu s~daty evidence úpadcù ÈR (viz \ref{sec:upadci}) jsme narazili na problém se~specifickımi formáty textu (pøedevším formát DOC). Automatické zpracování tìchto dat by bylo implementaènì nároèné a kladlo by pøemrštìné èasové nároky. Pro~potøeby experimentu jsme tato data zpracovali v~malém rozsahu ruènì.

Nesnadnım problémem je obecná automatizace pøedchozích dvou procedur. Napøíklad pro~stahování \uv{zajímavıch} èlánkù by se dal pouít univerzální web crawler nìjakého internetového vyhledávaèe, tím je napøíklad Egothor\footnote{http://www.egothor.org/} vyvíjenı tımem Lea Galamboše. Stránky, které tento crawler stahuje, by se filtrovaly pomocí heuristiky. Ta by vybrala stránky, které má cenu dále zpracovávat. Následuje problém, jak na~stránce automaticky najít texty, které nás zajímají. Pravdìpodobnì by se i tento problém dal øešit pomocí nìjaké heuristiky s~podporou metod pro konstrukci wrapper-u. Poznamenejme ještì, e Egothor kromì HTML zpracovává i zdroje ve~formátech PDF, PS, DOC a XLS.

Poslední transformace, kterou jsme pøed lingvistickım zpracováním textù provedli, byl pøevod kódování èeskıch znakù, pøeklad znakovıch entit HTML (\verb|&nbsp; &amp;| ...) a sjednocení zápisu èasovıch údajù (10:45 $\rightarrow$ 10.45, dvojteèku povaoval lingvistickı analyzátor za oddìlovaè slov, zatímco èasovı údaj zapsanı s~teèkou vyhodnocuje správnì). Tyto transformace se dají snadno automatizovat, pouze pøi pøevodu kódování èeskıch znakù musíme správnì urèit originální kódování zdroje.

Podrobnosti o~implementaci této fáze našeho experimentu je moné nalézt v~sekci \ref{sec:data_prepare}.

\subsection{Lingvistická anotace}
\label{sec:phase_ling_anot}
Tato fáze pøedstavuje pøevod prostıch textù na strukturovaná data lingvistickıch anotací. V~souèasné dobì nemáme na~vıbìr moc moností jak tuto fázi realizovat. Kromì lingvistickıch analyzátorù PDT, existují ještì nástroje vyvíjené na~Masarykovì univerzitì v~Brnì, o~nich se zmiòuje napøíklad práce \cite{Capek}. Bylo by jistì zajímavé v~experimentu obì varianty porovnat, ale u samotné poskládání nástrojù PDT bylo organizaènì pomìrnì nároèné, realizace tého s~brnìnskou stranou by práci èasovì protáhla a domníváme se, e by pro tuto práci nebyla \uv{pøevratnım} pøínosem. Tento potenciální pøínos ale nepopíráme.

V~našem experimentu se nyní nacházíme v situaci, kdy máme texty, které chceme analyzovat uloené v~prostıch textovıch souborech ve~správném kódování (ISO 8859-2). Spustíme jejich automatickou lingvistickou anotaci, která se skládá z~øetìzu nástrojù Tools for machine annotation - PDT 2.0 (viz sekce \ref{sec:anot_tools}) a nástroje pro~tektogramatickou analızu (sekce \ref{sec:t-nalysis}). Po delší dobì (lingvistická anotace je èasovì pomìrnì nároèná) získáme vıstup v~podobì lingvistickıch anotací na~všech rovinách popisu PDT, uloenıch ve formátu PML i PLS. Kvalita automaticky generovanıch lingvistickıch anotací se rùzní vìta od vìty. Domníváme se však, e pro typ aplikací, kterı zde simulujeme, je kvalita anotací více-ménì dostaèující.

Programová realizace této fáze experimentu je popsaná v~sekci \ref{sec:data_prepare}.

\subsection{Extrakce dat}
\label{sec:phase_data_extract}
V této fázi se budeme snait pomocí struktury lingvistickıch anotací extrahovat data obsaená v~pùvodních textech. Popíšeme zde \uv{øešení}, které jsme zvolili. Jedná se ale spíš o~prùzkum ne o~nìjakou ucelenou metodu. Pøí popisu tohoto øešení se budeme snait komentovat další alternativy a monosti.

\subsubsection{XML nebo btred?}
Nejprve jsme se chtìli s~daty blíe seznámit. V~tomto bodì jsme museli provést první rozhodnutí, toti jestli bude pro~naše úèely vhodnìjší na~programové úrovni pracovat s~lingvistickımi daty pøímo nebo prostøednictvím nástroje btred (popsanı v~sekci \ref{sec:tred}).

Lingvistická data ve~formátu PML jsou uloena jako~XML pomìrnì sloité struktury. Manipulace s~XML je v~souèasné dobì podpoøena širokou paletou programovıch nástrojù a nepøedstavuje pro~programátora velkou pøekáku, ale pøedpokládá detailní znalost struktury zpracovávanıch dat.

Btred, kterı nám byl lingvisty doporuèován, nabízí mnoho uiteènıch funkcí pro~manipulaci s~PML daty, tøi práci s~nástrojem btred tedy programátor nepotøebuje tak podrobné znalosti formátu PML, programátor ale musí zvládnout funkce tohoto nástroje. Jedinou moností, jak s~nástrojem btred pracovat, je naprogramování vlastního btred-makra, které pak tento nástroj nad~lingvistickımi daty vyhodnotí. Tato makra se zapisují v jazyce Perl, kterı je v~oblasti softwarovıch systémù zøídka pouívanı. Integrace btred-makra se zbytkem softwarového systému mùe bıt komplikovanìjší.

K~poèáteènímu prùzkumu jsme zvolili druhou variantu -- btred. Pro komplexní projekt by ale bylo vhodné tuto volbu ještì zváit a porovnat s monostmi vytvoøení a pouití dotazovacího jazyka nad lingvistickımi stromy, viz dále.

\subsubsection{Frekvenèní analıza}
Jako základní pohled na data nám poslouila frekvenèní analıza uzlù v~lingvistickıch stromech, konkrétnì analıza tektogramatickıch lemmat, zvláštì pak její podmnoina omezená pouze na~slovesa. Vısledky tìchto analız jsou uloeny v~souborech\footnote{Vısledky frekvenèních analız jsou uloeny v~souborech freq.txt a freq\_verb.txt pro~kadı datovı zdroj zvláš, konkrétnì v~adresáøích \emph{data/hasici} a \emph{data/upadci}.} \emph{freq.txt} a \emph{freq\_verb.txt} SVN repository. Èást vısledkù je grafickı zpracována na~obrázcích \ref{pict:freq_hasici} a \ref{pict:freq_upadci}.

\subsubsection{Pravidla pro extrakci dat}
Díky frekvenèním analızám jsme se mohli zamìøit na~ta tvrzení, která se v~textech èasto vyskytují. Vizuální prohlídka jednotlivıch vìt nám pak umonila vypozorovat ve~vìtách jednoduché vzory typu: Na slovese \texttt{zranit} visí pod~funktorem \texttt{PAT} podstrom vìty, kterı blíe specifikuje osoby, jich poèty, a druh zranìní, které utrpìly a tento podstrom má opìt ve~vìtšinì pøípadù podobnou strukturu. Na základì tìchto pozorování je moné zkonstruovat deterministická programová pravidla pro~extrakci dat. O~konstrukci nìkolika takovıch pravidel jsme se pokusili.

Ukázalo se, e naprogramování extrakèního pravidla pomocí nástroje btred pøedstavuje i pro~velmi jednoduchı vzor mnoho práce. Pøesto, e jsme se snaili program strukturovat do vìtšího mnoství obecnìjších funkcí a podprocedur, byl zápis pravidla velmi nepøehlednı. Tento závìr není pøekvapivı, více-ménì jsme ho pøedpokládali. Díky tomuto pokusu jsme ale podrobnìji poznali úskalí, která konstrukce tìchto pravidel pøináší.

\subsubsection{Zápis pravidel}
Programování extrakèních pravidel èistì pomocí nástroje btred nám ukázalo vıhody, které by pøinesl formální dotazovací jazyk nad~lingvistickımi stromy. Tento jazyk by dále umonil formalizovat pravidla pro~extrakci dat a formální zápis tìchto pravidel by umonil jejich uivatelskou editaci, strojovou indukci i sdílení. Bohuel ádnı takovı pøímo pouitelnı dotazovací jazyk pro~lingvistické stromy zatím není k~dispozici. V~oddíle \ref{sec:tree_query} jsme se pokusili o~návrh, jak takovı jazyk realizovat, a v~oddíle \ref{sec:patern_induction} se zamıšlíme nad~monostmi strojové indukce pravidel pro~extrakci dat.

\subsubsection{Vyuití WordNetu}
U v~zadání této práce je zmínka o~monosti vyuít databázi WordNet. Tato monost se nabízí právì zde. Pomocí lexikální sítì WordNetu by bylo moné zobecnit extrakèní pravidla. Napøíklad tam, kde bychom v~pùvodním extrakèním pravidle (bez WordNetu) poadovali pøesnou hodnotu tektogramatického lemma, bychom mohli povolit i jeho libovolné synonymum. Na jiném místì bychom mohli poadovat libovolné hyponymum pøípadnì libovolnı prvek podstromu lexikální dìdiènosti, napøíklad ve~zprávách o~dopravních nehodách bychom libovolné \emph{motorové vozidlo} nalezli v~podstromu lexikální dìdiènosti tohoto spojení.

Pøi~zkoumání èeského WordNetu jsme bohuel zjistili nedostateèné pokrytí èeské slovní zásoby a pomìrnì øídké provázání \emph{synsetù} sémantickımi hranami. Zvláštì patrné je to, pokud se zamìøíme na~nìjakou specifickou oblast, jako jsou napøíklad motorová vozidla. Nepovaujeme tedy za~pøínosné souèasnı èeskı WordNet pøímo na~extrakèní pravidla napojit. Na~druhou stranu se nemusíme vzdávat zobecnìní, které by sémantická lexikální sí pøinesla a mùeme na~základì WordNetu a dalších obdobnıch zdrojù takovou sí vytvoøit. Tato sí mùe bıt úzce specializovaná na~doménu ve~které se pohybujeme, nemusí zdaleka dosahovat rozsahu a plné obecnosti, která je na~WordNetu pozoruhodná.

Podrobnosti o~programovıch nástrojích, které jsme pro~zkoumání èeského WordNetu vyvinuly je moné nalézt v~sekci \ref{sec:wn_find}.

\subsubsection{Shrnutí}
V~praktickém experimentu jsme zjistili, e extrakci dat z~lingvisticky anotovanıch textù je moné provést pomocí extrakèních pravidel. Informace o~pravidlech, která jsme programovì realizovali pøedkládáme v~sekci~\ref{sec:extract_exp}. V~oddíle \ref{sec:tree_query} a na~obrázku \ref{pict:extract_patern} je moné nalézt konkrétní pøíklad realizovaného extrakèního pravidla.
 
Vytvoøení funkèních extrakèních pravidel je se souèasnımi programovımi prostøedky zbyteènì pracné a málo úèelné. Efektivní návrh a vyuití extrakèních pravidel by umonil dotazovací jazyk a jeho interpret nad~lingvistickımi stromy. Návrh realizace takového jazyka pøedkládáme v~oddíle~\ref{sec:tree_query}.

Další moností, jak extrahovat data z~lingvisticky anotovanıch textù, je zapojení nìkteré metody strojového uèení. Pro~tyto metody bychom musely vytvoøit trénovací data. Vytvoøení takovıch dat pøedstavuje mnoho ruèní práce, která však mùe bıt srovnatelná s~prací nutnou k~návrhu extrakèních pravidel.
%Zajímavou moností by mohla bıt kombinace obou pøístupù, toti metodou strojového uèení hledat extrakèní pravidla. ----- to je asi blbost ... museli bychom mít pravidla i tren. data
Za~nejlepší monost povaujeme poloautomatické vytvoøení extrakèních pravidel z~opakujících se vzorù ve~zkoumanıch datech. Diskuse nad~monostmi indukce takovıch vzorù je v~oddíle~\ref{sec:patern_induction}.

\subsection{Formální reprezentace dat}
Nacházíme se nyní v~situaci, kdy se nám podaøilo z~lingvisticky anotovanıch textù extrahovat data, která nás zajímají. Chtìli bychom je uchovávat v~takové formì, která by vystihovala jejich sémantiku. Vyuijeme tedy nìjakı konceptuální formální popis (ontologii), pomocí kterého data zapíšeme. Vznikne tak interpretace tìchto dat pomocí slovníku zvolené ontologie. Libovolnı programovı nástroj, kterı \uv{porozumí} dané ontologii, bude moci s~tìmito daty pracovat.

Technicky není tato fáze nároèná. Jedná se o~jednoduchou datovou transformaci, kterou je napøíklad pro~XML moné realizovat pomocí XSLT. V~našem experimentu jsme tuto fázi programovì nerealizovali, dùvodem byl mimo jiné nedostatek extrahovanıch dat.

Nároènost této fáze spoèívá v~nalezení, pøípadnì vytvoøení vhodné ontologie, pomocí které budeme data interpretovat. Je potøeba zváit všechny moné pøípady, ve~kterıch by se data dala pouít a najít takové øešení, které bude ve~vìtšinì pøípadù vyhovovat. Konkrétnì pouít rozšíøenou ontologii, pøípadnì maximálnì usnadnit mapování pouité ontologie na~koncepty ostatních. Pokud se podaøí konceptuálnì správnì data zachytit, vznikne skuteènì sémantická anotace tìchto dat, která není závislá na~úèelu jejich pouití.

Extrakèní vzory vzniklé v~pøedchozí fázi nejsou závislé na~vstupních datech, jsou závislé pouze na jazyce (na Èeštinì). Navíc tektogramatickı popis se snaí rozpouštìt rozdíly mezi jednotlivımi jazyky. Pøi pøekladu lemmat (napøíklad pomocí WordNetu a ILI -- viz oddíl \ref{sec:EuroWordNet}) by se tyto vzory mohli stát té na~jazyce nezávislé. Ovšem za~pøedpokladu, e bychom dokázali tektogramaticky analyzovat i ostatní jazyky a zdokonalili souèasnı EuroWordNet. Mohla by tak vzniknout databáze lingvisticko-sémantickıch vzorù, která by se dala sdílet a rozšiøovat v~širokém spektru projektù.



\section{Vstupní data}
\label{sec:data_in}
Dlouho jsme hledali vhodnı zdroj dat, na~kterém bychom pomocí experimentu ukázali vıhody lingvistického pøístupu k~extrakci informací a sémantické anotaci. Potøebovali jsme zdroj, kde jsou data vyjádøena pøirozenım jazykem ve~volném textu. K~tomu, aby naše automatická metoda mohla ukázat nìjakı pøínos proti prostému manuálnímu pøepisu dat, potøebujeme, aby se v~textech opakovali informace podobného typu a aby byly podobnì vyjádøeny. V~textech díky tomu mùeme najít vzory opakujících se tvrzení a pomocí nich hromadnì extrahovat data, která tato tvrzení nesou.

Tyto podmínky splòuje širší spektrum zdrojù. Uvaovali jsme o~anotaci analytickıch reportù o vısledcích dataminingu, o~èláncích otevøené encyklopedie Wikipedia, o~zprávách ze~sportovních zápasù i o~vıroèních zprávách podnikù ÈR. Vıhody sémanticky anotovanıch reportù zmiòujeme u v~úvodu (sekce \ref{sec:data_mine}).  V~pøípadì Wikipedia encyklopedie bychom naše sémantické anotace mohli ukládat pomocí SMW (viz sekce \ref{sec:SMW}) a pøispívat tak k~vytvoøení sémantické Wikipedie. V~tomto pøípadì bychom se ale museli zamìøit na~nìjakou uší oblast èlánkù.

Nakonec jsme vybrali dva pomìrnì odlišné zdroje: hasièské zpravodajství a databázi úpadcù ÈR. Hlavními dùvody tohoto rozhodnutí byla vysoká míra opakování se podobnıch témat ve~zprávách a pomìrnì snadná dostupnost tìchto dat. Oba zdroje podrobnìji popíšeme níe.

Další ponìkud odlišnou moností vstupních dat pøedstavuje korpus PDT. V~tomto pøípadì bychom se mohli opøít o~velmi kvalitní \uv{ruèní} lingvistické anotace. Data korpusu PDT jsou pestrá a opakující témata bychom zde hledali obtínì. Navíc dùraz experimentu byl kladen na co moná nejvìtší pøiblíení se k~podmínkám a problémùm skuteèného projektu. V~takovém pøípadì bychom se tìko mohli opøít o~to, e by nám data která chceme analyzovat nìkdo ruènì lingvisticky anotoval. Nicménì pokusy s~ruèními lingvistickımi anotacemi dat PDT\footnote{Jedná se o \emph{sample data} PDT 2.0, http://ufal.mf\/f.cuni.cz/pdt2.0/data/sample/} (pøedevším z~tréninkovıch dùvodù) probìhly.

\subsection{Hasièi}
\label{sec:hasici}
Ministerstvo vnitra Èeské republiky pravidelnì zveøejòuje krátké zprávy o~akcích, kterıch se úèastnily hasièské sbory jednotlivıch regionù ÈR. Tyto zprávy se nám z~vıše zmínìnıch dùvodù zdály vhodné jako zdrojová data experimentu. Tyto èlánky jsou k~dispozici na internetovém portálu MVÈR jako \uv{Bleskové hasièské zpravodajství RSS z~regionù}\footnote{http://www.mvcr.cz/rss/regionhzs.html}. Odtud je pomocí programovıch nástrojù (popsanıch v~sekci \ref{sec:data_prepare}) stahujeme a dále zpracováváme. Aktuálnì zpracovávanı archiv obsahuje pøiblinì 500 èlánkù (celkem cca 1MB textovıch dat).

Tyto zprávy se nejèastìji tıkají vıjezdu hasièskıch oddílù k~dopravní nehodì nebo poáru, ménì èasto informují o~rùznıch hasièskıch slavnostech a dalších zásazích hasièské sluby (ochrana vodních zdrojù pøed chemickım zneèištìním, opatøení proti ptaèí chøipce, kuriózní nehody v~domácnostech). Následuje úryvek z~jedné zprávy\footnote{http://www.mvcr.cz/rs\_atlantic/project/article.php?id=59311}.

\begin{quote}
Na 241,5 kilometru dálnice D1 ve smìru na Kromìøí havaroval tahaè Volvo s návìsem. Souprava jedoucí v levém, rychlém jízdním pruhu zezadu narazila do dvou speciálních vozidel správy a údrby dálnic – do dodávky Renault s varovnou svìtelnou šipkou a do traktoru k údrbì dálnice. V kabinì tahaèe Volvo byli zranìni 25letı øidiè a jeho desetimìsíèní dítì. Jednadvacetiletá matka dítìte vyvázla bez zranìní. Do nemocnice byli pøevezeni také øidièi speciálních vozidel – 35letı øidiè dodávky Renault a 34letı øidiè traktoru, kterı ale byl po ošetøení propuštìn.
\end{quote}

\begin{figure}[t!]
  % Requires \usepackage{graphicx}
\begin{center}
  \includegraphics[scale=0.54]{../freq_hasici.eps}
  \includegraphics[scale=0.54]{../freq_verb_hasici.eps}\\
\end{center}

  \caption[Frekvenèní analıza hasièskıch zpráv]{Frekvenèní analıza hasièskıch zpráv -- vpravo pouze slovesa.}
  \label{pict:freq_hasici}
\end{figure}


\subsection{Úpadci}
\label{sec:upadci}
Na Informaèním serveru èeského soudnictví\footnote{http://portal.justice.cz/} je veøejnì dostupná \emph{Evidence úpadcù} Ministerstva spravedlnosti Èeské republiky. Tato rozsáhlá a neustále aktualizovaná evidence obsahuje kromì dalších dat i texty jednotlivıch soudních rozhodnutí a ustanovení. Právì tyto texty jsme zvolili jako vstupní data experimentu.

Automatické staení a proèištìní dat z~tohoto datového zdroje by bylo pomìrnì komplikované. Texty jsou na~serveru uloené ve~formátu DOC, k~tìmto dokumentùm neexistují perzistentní URL, stahování jednotlivıch dokumentù probíhá pøes náhodnou doèasnì zvolenou adresu, která vzniká pøi generování web-stránky s detailním popisem kadého konkurzu. Ještì nároènìjší by však bylo automaticky extrahovat texty, které nás zajímají z~jednotlivıch DOC souborù. Tyto soubory nemají jednotnou strukturu, jsou napsané rùznımi autory, jsou rùznì formátované, texty ustálenıch nadpisù se vyskytují v~nìkolika variantách.

Tento datovı zdroj hraje v~našem experimentu spíše doplòkovou roli. Chtìli jsme porovnat kvalitu lingvistickıch anotací a monosti naší metody na~datech v~další doménì. K~tomuto úèelu jsme tato data zpracovali v~malém rozsahu ruènì, jsou uloena v~souboru \emph{data/upadci/sample\_data.txt} SVN repository. Z~testu, kterı jsme provedli na~zmínìném vzorku dat se ukazuje, e automaticky generované lingvistické anotace jsou i v~tomto pøípadì pouitelné. Lingvistické analyzátory si velmi dobøe poradily napøíklad s~èlenìním a èíslováním paragrafù jednotlivıch zákonù. Problémy se ukazují pøi analıze nìkterıch témìø a neuvìøitelnıch souvìtí o~délce pøes ètyøicet slov.

\pagebreak
Následuje úryvek z~textu jednoho soudního usnesení.

\begin{quote}
Rozdìlení vıtìku získaného zpenìením konkurzní podstaty vychází z údajù obsaenıch ve schválené koneèné zprávì a bylo provedeno v souladu s ust. § 31 a 32 zák. o konkurzu a vyrovnání.  Po odeètení nákladù spojenıch se správou a údrbou konkurzní podstaty, pøiznání odmìny správci, nároku oddìleného vìøitele a vymìøení soudního poplatku, zùstala k rozdìlení mezi vìøitele II. tøídy èástka 15,921.636,70 Kè, která bude rozdìlena v pomìru 14,927871 \% zjištìnıch pohledávek. Tím bude celá konkurzní podstata vyèerpána.
\end{quote}


\begin{figure}[b!]
  % Requires \usepackage{graphicx}
\begin{center}
  \includegraphics[scale=0.55]{../freq_upadci.eps}
  \includegraphics[scale=0.55]{../freq_verb_upadci.eps}
\end{center}

  \caption[Frekvenèní analıza evidence úpadcù]{Frekvenèní analıza evidence úpadcù -- vpravo pouze slovesa.}

  \label{pict:freq_upadci}
\end{figure}

%\section{Vıstupní data}
%Vzhledem k tomu, e pojem sémantické anotace, jak ho zmiòuji v kapitole \ref{sec:sem_anotace}, je velmi širokı, není ani pøesnì urèeno, jaká data by pøi procesu sémantické anotace mìla vzniknout.

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Software}
Pro ukládání a verzování programové èásti práce jsme vyuili slueb veøejného serveru BerliOS\footnote{Naše stránky zde mají adresu http://czsem.berlios.de/}, kde nám byl poskytnut úèet spolu s~veøejnım SVN repository\footnote{Adresa naší SVN repository: http://svn.berlios.de/svnroot/repos/czsem/trunk/}. V~tomto SVN úloišti je moné nalézt aktuální verze softwarovıch komponent i textù této práce. Na CD-ROM pøiloeném k~této práci je v~adresáøi \emph{czsem} umístìna kopie SVN repository ve~verzi z~10.~8. Chystáme se však práci dále vyvíjet, proto doporuèujeme data v~SVN repository na~pøiloeném CD-ROM pøed pouíváním èi prohlíením aktualizovat (Pro~podrobnosti viz soubor ReadMe.txt na~pøiloeném CD-ROM).

\subsection{Instalace}
\label{sec:install}

Pro otestování jednotlivıch programovıch èástí je nutná pomìrnì komplikovaná instalace pouitıch lingvistickıch nástrojù. K~publikaci nìkterıch z~nich navíc nemáme svolení. Ètenáø, kterı pravdìpodobnì bude chtít programovou èást práce vyzkoušet, má dvì monosti. Buï si všechny nástroje i s~licencí pro~jejich pouívání obstará sám nebo se mùe obrátit na~autory práce a vyádat si zapùjèení tìchto nástrojù za~úèelem testování této práce -- tato èinnost pak bude pokryta platnou licencí autorù práce. Druhá varianta zahrnuje i propùjèení uivatelského úètu (vèetnì hesla) pro~pøístup k~webovému rozhraní èeského WordNetu (pro~podrobnosti o~èeském WordNetu viz~\ref{sec:wordnet_cz}).

Postup instalace vèetnì odkazù na~poskytovatele jednotlivıch nástrojù je popsanı v~souboru \emph{install.txt}\footnote{Soubor install.txt je umístìnı v~adresáøi \emph{docs/UserGuide} SVN repository.}.

Autoøi práce jsou si vìdomi toho, e pokud by chtìli svùj software veøejnì publikovat nebo dokonce prodávat, bylo by nutné instalaci zjednodušit a ošetøit právní nároky tøetích stran. To ale nebylo pøedmìtem tohoto experimentu. Problematiku instalace externích komponent ponechme jejich autorùm. Nejménì pøíjemná je instalace tektogramatického analyzátoru (sekce \ref{sec:t-nalysis}), tento nástroj je ale stále ve~vıvoji a jeho instalaci je nutné povaovat za~doèasné øešení.

\pagebreak
\subsection{Skripty pro pøípravu dat}
\label{sec:data_prepare}
Skripty, pomocí kterıch se stáhnou a transformují stránky hasièského zpravodajství jsou umístìné v~adresáøi \emph{data/hasici} SVN repository. Jedná se o~sadu \emph{bash} skriptù, které by mìli fungovat na vìtšinì UNIX-ovıch systémù. Pøed jejich spuštìním je nutné do~systému nainstalovat potøebné lingvistické nástroje (pro popis instalace viz \ref{sec:install}). Kompletní dávku spustíme (na~pozadí) skriptem \emph{run\_parse\_background}. Tato dávka postupnì vykoná všechny akce popsané v~sekcích \ref{sec:phase_data_prepare} a \ref{sec:phase_ling_anot}. Vıstupní lingvistické anotace budou uloeny v~adresáøi \emph{data/hasici/pml}. Celı bìh této dávky mùe trvat i více ne tøi hodiny. Hlášení o~prùbìhu jednotlivıch akcí je zaznamenáváno v~log-souboru \emph{parse.log}. Podrobnosti k~funkci jednotlivıch skriptù je moné nalézt v~komentáøích uvnitø kadého skriptu.


\subsection{Makra pro extrakci dat}
\label{sec:extract_exp}
V~prùbìhu experimentu jsme vytvoøili nìkolik maker pro~nástroj btred (sekce \ref{sec:tred}). Jednalo se o~makra pro~frekvenèní analızu, makra pomocí kterıch jsme podrobnìji zkoumali vstupní data a makra která simulují extrakci dat. Pøíklad extrakèního pravidla, které jsme se pokusili realizovat je znázornìno v~sekci \ref{sec:extract_rule}.

Všechny tyto makra (Perl-skripty) jsou umístìny v~adresáøi \emph{src/perl} SVN repository. Podrobnosti o~jednotlivıch makrech je moné nalézt v~souboru \emph{src/perl/info.txt} a v~komentáøích uvnitø kódu jednotlivıch skriptù.

%Napøíklad frekvenèní analıza hasièskıch dat probíhá pomocí skriptu \emph{data/hasici/freq.btred} v~SVN repository.


\subsection{Hledání pøíbuznıch slov pomocí WordNetu}
\label{sec:wn_find}
Èeskı WordNet jsme prohlíeli pomocí vizuálního prohlíeèe DEBVisDic (viz oddíl \ref{sec:wordnet_cz}) a pomocí jednoduchého vlastního programového nástroje, kterı jsme k~tomuto úèelu vytvoøili v~jazyce Java. Tento nástroj pøistupuje k~èeskému WordNetu pøes web-rozhraní té zmínìné v~oddíle \ref{sec:wordnet_cz}. Nástroj umoòuje hledat ve~WordNetu libovolné slovo èi slovní spojení, stahovat jednotlivé synsety ve~formátu XML a obsahuje i funkci, která pro~danı synset získá úplnou øadu hyperonym a ke~koøenu lexikální dìdiènosti. Pro~dvì takové øady pak umí nalézt jejich prùnik.

Tento nástroj je moné nalézt v~adresáøi \emph{src/wordnet} SVN repository. Podrobnìjší popis tohoto nástroje je v~souboru \emph{WordNet\_info.txt}, implementaèní detaily jednotlivıch funkcí jsou komentovány ve~zdrojovıch kódech.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Návrhy a zkušenosti}
\section{Dotazování nad lingvistickımi stromy}
\label{sec:tree_query}
Bìhem našeho experimentu jsme narazili na~potøebu dotazovacího jazyka, pomocí kterého bychom se mohli programovì dotazovat na~hodnoty atributù lingvistickıch stromù a pomocí kterého by bylo moné obecnì zachytit strukturu podobnıch vìt (vzorù), které se v~datech vyskytují. Dotazovací jazyk, kterı pouívá aplikace Netgraph (viz sekce \ref{sec:netgraph}), je naší pøedstavì velmi blízkı.

%Vytvoøení takovıch funkèních pravidel je ale se souèasnımi programovımi prostøedky zbyteènì pracné a málo úèelné. Efektivní návrh a vyuití extrakèních pravidel by umonil dotazovací jazyk a jeho interpret nad~lingvistickımi stromy. Návrh takového jazyka pøedkládáme v~oddíle \ref{sec:tree_query}.

%kapitola Netgraph:: V prùbìhu experimentu, kterı je popsán v~kapitole \ref{sec:experiment}, jsme narazili na~potøebu dotazovacího jazyka, pomocí kterého bychom se mohli programovì dotazovat na~hodnoty atributù lingvistickıch stromù. Té by se nám velmi hodil jazyk, ve kterém by bylo moné vyjádøit vzory stromù, které se v~korpusu našeho experimentu èastìji vyskytují. Dotazovací jazyk, kterı pouívá aplikace Netgraph, je naší pøedstavì velmi blízkı. Tuto problematiku podrobnìji rozebíráme v~oddíle \ref{sec:tree_query}.

\subsection{Dotazovací jazyk aplikace Netgraph}
Nyní se pokusíme struènì popsat dotazovací jazyk aplikace Netgraph. Podrobnı popis tohoto jazyka je moné nalézt v~manuálu aplikace Netgraph\footnote{http://quest.ms.mf\/f.cuni.cz/netgraph/doc/netgraph\_manual.html}, pøípadnì v~\cite{mirovsky_netgraph}.

Definovat dotaz v~tomto jazyce, znamená definovat podstrom, kterı se má v~prohledávanıch stromech vyskytovat. Tento dotazovací jazyk tedy umoòuje definovat strukturu stromu. Navíc mùeme v~kadém uzlu dotazu omezit hodnoty atributù daného uzlu.

\subsubsection{Linearizace struktury stromu}
Dotazy v~jazyce, kterı popisujeme, se zapisují lineárnì jako textové øetìzce. Ukáeme nyní, jak strukturu stromu dotazu pøevedeme do~lineárního zápisu dotazu.

Kadı jednotlivı uzel je v~dotazu zapsán mezi dvojici hranatıch závorek \verb|[ ]|.
Za~tìmito závorkami následuje v~kulatıch závorkách èárkami oddìlenı seznam jeho dìtí, napøíklad \verb|([],[])|. Zápis dotazu tedy zaèíná u~koøene a podle pøedchozích dvou pravidel postupuje a k~listùm stromu dotazu. Na~obrázku \ref{pict:tree_linearize} je znázornìn strom s~pìti uzly, kterı zapíšeme jako \verb|[]([]([],[]),[])|. Èísla uzlù na obrázku odpovídají poøadovému èíslu hranatıch závorek, které danému uzlu v~zápisu odpovídají.

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.8]{../NetGraph1.eps}
\end{center}
  \caption{Linearizace stromu v~dotazovacím jazyce Netgraph}
  \label{pict:tree_linearize}
\end{figure}

\subsubsection{Atributy uzlù}
V~kadém uzlu dotazu je moné omezit hodnoty jeho atributù. Tato omezení zapisujeme mezi hranaté závorky, které mu v~lineárním zápisu dotazu pøísluší. Tato omezení se píší ve tvaru \emph{název atributu} \verb|=| \emph{hodnota atributu}, pøípadnì \verb|!=|, \verb|<|, \verb|<=|, \verb|>|, \verb|>=|. Jednotlivá omezení uvnitø kadého uzlu oddìlujeme èárkami. Operátorem \verb+|+ mùeme zapsat alternativní hodnoty, pomocí zástupnıch znakù \verb|?| (libovolnı znak) a \verb|*| (libovolnı øetìzec) mùeme hodnotu atributu zobecnit.

Napøíklad zápis \verb+[t_lemma=hasiè,functor=ACT|PAT,gram/sempos=n.*]+ omezuje tektogramatické lemma tohoto uzlu na~hodnotu \emph{hasiè} a funktor na hodnotu \emph{ACT} nebo \emph{PAT} a sémantickı slovní druh (gram/sempos) na~hodnoty zaèínající \emph{n.} tedy libovolná sémantická substantiva.

Kromì atributù, které jsou spojeny s~daty lingvistickıch anotací, mùeme v~dotazech pouívat ještì takzvané \emph{meta-atributy}, pomocí kterıch je moné dotaz dále upøesnit. Uveïme nyní nìkteré z~nich s~krátkım popisem.

\begin{center}
\begin{tabular}{rl}
  \verb|_optional| & Umoòuje vypustit tento uzel z~dotazu.\\
  \verb|_transitive| & Deklaruje tranzitivní hranu stromu.\\
  \verb|_#occurrences| & Umoòuje omezit délku tranzitivní hrany.\\
  \verb|_depth| & Vzdálenost od~koøene stromu.\\
  \verb|_name| & Nastavuje jméno uzlu.\\[1pt]
  \verb|hide| & Definuje skrytı uzel (viz dále).
\end{tabular}
\end{center}


Atribut \emph{\_name} v~dotazech umoòuje pouít referenci na~libovolnı pojmenovanı uzel. Pøi~omezování hodnoty nìkterého atributu se mùeme pomocí reference odkázat na~hodnoty atributù referenèního uzlu. Napøíklad zápisem \verb|[a/ord<{N1.a/ord}]| vyjádøíme, e poøadí tohoto uzlu ve~vìtì (hodnota atributu \emph{a/ord}) má bıt niší ne poøadí uzlu se jménem \emph{N1}. Podrobnosti o~referencích je moné nalézt v~manuálu aplikace Netgraph.


\subsubsection{Skryté uzly a roviny lingvistické anotace}
Pomìrnì elegantnì je v~aplikaci Netgraph vyøešen pøechod z~tektogramatické roviny na~rovinu analytickou. Obì tyto roviny lingvistického popisu jsou v~aplikaci Netgraph spojeny. Od~kadého tektogramatického uzlu vedou hrany ke~všem odpovídajícím analytickım uzlùm. Analytické uzly jsou pøímo zavìšeny na~tektogramatickıch jako jejich listy -- z~analytickıch uzlù u ádné hrany nevedou.

Aby bylo moné tektogramatické uzly od~analytickıch snadno oddìlit, jsou analytické uzly v~Netgraphu oznaèeny jako skryté. Dotazy se standardnì na~skrytıch uzlech nevyhodnocují.
V~dotazu na~skryté analytické uzly, musíme u~všech uzlù dotazu, které mají odpovídat skrytım uzlùm dat, nastavit meta atribut \verb|hide=true|.


\subsubsection{Pøíklad}
%[_name=action_type,gram/sempos=v,t_lemma=zranit|usmrtit|zemøít|zahynout|pøeít]([m/tag=??????????N*,_name=a-negation,hide=true,_optional=true],[functor=MANN,_name=injury_manner,_optional=true],[functor=ACT|PAT,t_lemma=kdo|èlovìk|osoba|mu|ena|dítì|øidiè|øidièka|spolujezdec|spolujezdkynì,_name=participant]([functor=RSTR,gram/sempos=n.quant.*|adj.quant.*,_optional=true,_name=quantity]))
Uvedeme nyní vìtší pøíklad dotazu v~popisovaném dotazovacím jazyce. Jedná se o~souèást extrakèního pravidla, které jsme se pokusili programovì realizovat v~rámci fáze \ref{sec:phase_data_extract}. Naprogramování extrakèního pravidla, které pøiblinì odpovídá tomuto dotazu, bylo pomocí nástroje btred nároèné. Rozsáhlé btred makro s~mnoha podprocedurami, které vyhodnocuje tento dotaz, mùeme nahradit nìkolika øádky dotazu aplikace Netgraph.

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.54]{../extract_patern.eps}
\end{center}
\begin{verbatim}
[ _name=action_type,
  gram/sempos=v,
  t_lemma=zranit | usmrtit | zemøít | zahynout | pøeít ]
( [ _name=a-negation,
    m/tag=??????????N*,
    hide=true,
   _optional=true ],
  [ _name=injury_manner,
    functor=MANN,
    _optional=true ],
  [ _name=participant,
    functor=ACT | PAT,
    t_lemma=kdo | èlovìk | osoba | mu | ena | dítì |
      øidiè | øidièka | spolujezdec | spolujezdkynì ]
  ( [ _name=quantity,
      functor=RSTR,
      gram/sempos=n.quant.* | adj.quant.*,
      _optional=true ] ) )
\end{verbatim}

  \caption{Pøíklad extrakèního vzoru jako dotaz Netgraphu}
  \label{pict:extract_patern}
\end{figure}

Na~obrázku \ref{pict:extract_patern} mùeme nalézt graficky znázornìnı dotaz spolu se~svım lineárním zápisem. Je zde vidìt, e lineární zápis dotazu není moc pøehlednı. Na~druhou stranu návrh a uivatelská manipulace s~tìmito dotazy mùe probíhat v~grafickém rozhraní, podobnì jako v~Netgraph klientu (viz \ref{sec:netgraph}).

Popišme nyní struènì pøíklad na~obrázku \ref{pict:extract_patern}. Èísla v~tomto popisu odpovídají èíslùm uzlù na~obrázku.

\begin{enumerate}
  \item Uzel \verb|action_type| -- Hlavní sloveso pravidla.
  \item Uzel \verb|a-negation| -- Hledáme negaci slovesa \verb|action_type|. Protoe automatickı tektogramatickı analyzátor nevyplòuje atribut \emph{gram/negation}, hledáme negaci na~analytické rovinì uvnitø morfologické znaèky \emph{m/tag}.
  \item Uzel \verb|injury_manner| -- Druh zranìní, napøíklad lehce / tìce.
  \item Uzel \verb|participant| -- Postiené osoby.
  \item Uzel \verb|quantity| -- Poèet postienıch osob, hodnoty \emph{n.quant} a \emph{adj.quant} zastupují kvantifikaèní substantiva a adjektiva.
\end{enumerate}

\noindent Tomuto dotazu vyhovují napøíklad vìty:
\begin{quote}
Pøi nehodì nebyl nikdo zranìn.\\[5pt]
Pìt osob bylo zranìno tìce, dvì lehce.\\[5pt]
Øidiè automobilu nehodu nepøeil.
\end{quote}


\subsubsection{Interpretace}
Pokud bychom zde popisovanı dotazovací jazyk chtìli pouít pøi extrakci informací, potøebovali bychom interpret, kterı dotaz nad lingvistickımi daty vyhodnotí a vrátí nám vısledek. Tento interpret by navíc musel bıt dostupnı skrz nìjaké programové API.

Aplikace Netgraph je urèena k~prohledávání korpusu PDT a podobnıch. Je zamìøena na~uivatelsky pohodlnı návrh dotazu a pøehledné zobrazení vısledkù. Dotazovací jazyk zde hraje roli prostøedku pro~pøedání dotazu serveru, kterı ho nad~korpusem vyhodnotí. Vıvoj tohoto jazyka je souèástí celé aplikace a oddìlenı interpret jazyka s~programovım API zatím není k~dispozici.

Kontaktovali jsme správce aplikace Netgraph -- Jiøího Mírovského a získali pøedbìnı pøíslib spolupráce pøi~tvorbì oddìleného interpreta pro~zmínìnı dotazovací jazyk. Varianta, kdy by tento interpret vystupoval jako další klient aplikace Netgraph, by pro~svou realizaci potøebovala pouze dokumentaci komunikaèního protokolu mezi klientem a serverem aplikace Netgraph. Vytvoøení této dokumentace je té souèástí vlastního plánu vıvoje aplikace Netgraph.



\subsection{Extrakèní pravidla}
\label{sec:extract_rule}
Extrakèní pravidla pro~získávání dat z~lingvisticky anotovanıch textù se skládají z~dotazu a z~jeho zpracování. V~dotazu specifikujeme, jaká data hledáme. Pøi zpracování vısledku urèíme, jakou podobu budou mít nalezená data ve~vıstupu extrakèního procesu.

Pro ukázku nyní zkonstruujeme dva pøíklady, jak by taková extrakèní pravidla mohla vypadat. V~obou pøíkladech zafixujeme èást \uv{lingvistického} dotazu na~dotaz v~jazyce aplikace Netgraph z~pøedchozího textu. Tedy dotazem bude právì text z~obrázku \ref{pict:extract_patern}. První pøíklad formátuje vıstup extrakèního pravidla jako tabulku relaèní databáze. Druhı pøíklad je inspirovanı dotazovacím jazykem XML-QL\footnote{XML-QL: A Query Language for XML, http://www.w3.org/TR/NOTE-xml-ql/} a jeho vıstupem jsou data ve~formátu XML.

\subsubsection{SQL tabulková forma pravidla}
\begin{verbatim}
    SELECT action_type.t_lemma, a-negation.m/tag, 
           injury_manner.t_lemma, participant.t_lemma,
           quantity.t_lemma
    FORM *** text Netgraph dotazu ***
\end{verbatim}

\subsubsection{XML-QL forma pravidla}


\subsubsection{Další monosti}


\subsection{Indexace}
\label{sec:tree_indexing}

Indexace XML dat (pro optimalizaci vyhodnocování dotazù XPath, XQuery a podobnıch) je v~souèasnosti otevøenım problémem. Stále ještì hledáme algoritmus, kterı by dokázal efektivnì indexovat XML data libovolné struktury. Tuto situaci ilustrují napøíklad èlánky
\cite{saptial_index}, \cite{baca_znalosti}.


\section{Indukce vzorù}
\label{sec:patern_induction}
klasifikace - dendrogram
od frekvenèní analızy lemmat dále po rùznıch osách struktury, rùzné délky tranzitivních hran stromu, zahrnou rùzné atributy

konstrukce dendrogramu interaktivní, napø. se fixují jednotlivá lemmata

pøevod vzoru na pravidlo: uivatel oznaèí atributy které ho zajímají, zapíše transformaci vıstupu na formální reprezentaci znalostí (4. krok osnovy), lze té vizualizovat ontologii a mapovat vizuálnì.

Oznaèí korpus a nasadit strojové uèení.
.. pravidla by vznikala jako èerná - a šedá skøíòka
.. problém s vytváøením korpusu, ruèní anotace


\section{Závìr práce}
Otevírá mnoho moností

široké téma, citovat zadání -- úvodní práce, otevøení tohoto téma

Základní prùzkum
\\- teoretickı
\\- praktickı
\\navádí na~zaèátek, kdekoliv je moné pokraèovat