\documentclass[authoryear,12pt]{elsarticle}

\usepackage{graphicx} % Add all your packages here

\usepackage[cp1250]{inputenc}  % or [cp1250], or [latin2], or whatever
                               % suitable for your system


\usepackage{url}
%\usepackage{floatflt}
\usepackage{wrapfig}
\usepackage{amsthm}


\journal{Information Processing \& Management}

\begin{document}

\begin{frontmatter}


\title{Fuzzy Classification of Web Reports with Mining from Texts with Linguistic Annotations}
%
%\author{Jan Dedek and Peter Vojtas\\
%Department of Software Engineering, Charles University\\
%Institute of Computer Science, Czech Academy of Science\\
%Prague, Czech Republic\\
%email: \{jan.dedek, peter.vojtas\}@mff.cuni.cz
%%\and
%%Peter Vojtas\\
%%Department of Software Engineering, Charles University\\
%%Institute of Computer Science, Czech Academy of Science\\
%%Prague, Czech Republic\\
%%peter.vojtas@mff.cuni.cz\\
%}

%\author{Jan D\v{e}dek, Peter Vojt\'a\v{s}, Marta Vomlelov\'a}
\author[1]{Jan D\v{e}dek}
\ead{dedek@ksi.mff.cuni.cz}
\author[1]{Peter Vojt\'a\v{s}}
\ead{vojtas@ksi.mff.cuni.cz}
\author[2]{Marta Vomlelov\'a}
\ead{marta@ktiml.mff.cuni.cz}

\address[1]{Department of Software Engineering, Charles University,\\
Prague, Czech Republic}
\address[2]{Department of Theoretical Computer Science and Mathematical Logic,\\
Charles University, Prague, Czech Republic}

\begin{abstract}
In this paper we present a fuzzy system, which provides a fuzzy
classification of textual web reports. Our approach is based on usage
of third party linguistic analyzers, our previous work on web
information extraction and fuzzy inductive logic programming. Main
contributions are: formal models, prototype implementation,
extensive evaluation experiments and comparison of our classifier with other
alternatives like decision trees, support vector machines, neural
networks etc.
\end{abstract}

\begin{keyword}
Fuzzy \sep
Inductive Logic Programming \sep
Information Extraction \sep
Natural Language Processing \sep
Machine Learning
%fuzzy \sep inductive logic programming \sep text mining
%% keywords here, in the form: keyword \sep keyword

%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)
\end{keyword}

\end{frontmatter}


\section{Introduction}
Big amount of information on the web increases the need of automated processing. Especially machine processing and machine understanding of textual information is very difficult. Crisp methods have their limitations. In this paper we present a fuzzy system, which provides a fuzzy classification of textual web reports. 

\begin{figure}[hbt!]
\centerline{\includegraphics[width=0.7\hsize]{img/message}}
\caption{Example of analyzed web report.}
\label{img:message}
\end{figure}


Our motivating examples are messages of accident reports on the web (Fig.~\ref{img:message}). We would like to have a tool, which is able to classify such message by a degree of being it a serious accident. 

Our solution is based on information extraction (see the emphasized pieces of information that could be extracted from a report in the Fig.~\ref{img:message}) and on a machine learning procedure that provides rules for fuzzy classification of the reports. Our experiments deal with texts in the Czech language but our method is general and can be used with any structured linguistic representation. In this paper we do not provide many details about the information extraction part of the solution. We concentrate on the classification part.



The main contributions of this paper can be stated as follows: 
\begin{itemize}
	\item formal models for fuzzy classification of information from web reports
	\item prototype implementation and %of a fuzzy classification system
	\item experimental evaluation of our fuzzy classification system.
\end{itemize}

Our paper is organized as follows: In the section~\ref{sec:related} we introduce some works that are closely related to ours. In section~\ref{sec:models} we develop our models and methods and the design of our system, focusing on the description of linguistic analyzers, inductive logic programming (ILP), fuzzy inductive logic programming (fuzzy ILP) and several translations of a fuzzy ILP task to crisp ILP. In the section~\ref{sec:prototype_and_experiment} we describe the system prototype implementation, the data and our evaluation experiment. In the section~\ref{sec:results} we present the results of~the~experiment and compare our methods with other classifiers, which are well-known in machine learning. The section~\ref{sec:conclusion} concludes the paper.



\section{Related Work} \label{sec:related}

There are plenty of systems dealing with text mining and text classification. In \citep{dedek:ReYaLiOntoText08} the authors use ontology modeling to enhance text identification. The authors of \citep{dedek:CAP} use preprocessed data from National Automotive Sampling System and test various soft computing methods to modeling severity of injuries (some hybrid methods showed best performance). Methods of Information Retrieval (IR) are very numerous, with extraction mainly based on key word search and similarities. The Connection of IR and text mining techniques with web information retrieval can be found in Chapter Opinion mining in the book of Bing Liu \citep{dedek:WebDataMining}. 

%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Models, methods, design of the system} \label{sec:models}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{wrapfigure}[22]{r}{.45\hsize}
\vspace{-0.5cm}
\centerline{\includegraphics[width=\hsize]{img/schema}}
\caption{Schema of our system.}
\label{img:schema}
\end{wrapfigure}

%\begin{floatingfigure}[r]{.45\hsize}
%\centerline{\includegraphics[width=\hsize]{img/schema}}
%\caption{Schema of the whole system.}
%\label{img:schema}
%\end{floatingfigure}

A general schema of our experimental system is shown on the Fig.~\ref{img:schema}. We use our previously developed web information extraction tools based on third party linguistic analyzers (the upper two dashed arrows, this is not a subject of this paper). We extract some structured information from the web and the extracted information is then translated to an ILP knowledge base and along with an user rating it is used for the classification. (We assume that a small amount of learning data is annotated by a human user.) The classification is based on ILP and it could be \emph{fuzzy} or \emph{crisp} (see in next sections).


%\begin{figure}[hb!]
%\centerline{\includegraphics[width=.7\hsize,height=\hsize]{img/schema}}
%\caption{Schema of the whole system.}
%\label{img:schema}
%\end{figure}



\subsection{Linguistic Analysis}
In this section we will briefly describe the linguistic tools that
we have used to produce linguistic annotations of texts. 
These tools are being developed in the Institute of Formal
and Applied Linguistics in Prague, Czech Republic. They
are publicly available -- they have been published on a CDROM
under the title PDT 2.0 (\cite{dedek:PDT20_CD} -- first five tools) and in
(\cite{dedek:KlTransformationBasedTectogrammatical2006} -- Tectogrammatical analysis). These tools are used as a
processing chain. At the end of the chain they produce
tectogrammatical \citep{dedek:MiBeAnnotationtectogrammatical2006} dependency trees built up from the text.


\begin{description}
 
	\item[Tool 1.] Segmentation and tokenization consists of tokenization
(dividing the input text into words and punctuation)
and segmentation (dividing a sequences of tokens
into sentences).

	\item[Tool 2.] Morphological analysis assigns all possible lemmas
and morphological tags to particular word forms (word
occurrences) in the text.

	\item[Tool 3.] Morphological tagging consists in selecting a single
pair lemma-tag from all possible alternatives assigned
by the morphological analyzer.

	\item[Tool 4.] Collins' parser -- Czech adaptation. 
Unlike the usual approaches to the description of
English syntax, the Czech syntactic descriptions are
dependency-based, which means, that every edge of
a syntactic tree captures the relation of dependency
between a governor and its dependent node. Collins'
parser gives the most probable parse of a given input
sentence.

	\item[Tool 5.] Analytical function assignment assigns a description
(analytical function -- in linguistic sense) to every edge
in the syntactic (dependency) tree.

	\item[Tool 6.] Tectogrammatical analysis produces linguistic annotation
at the tectogrammatical level, sometimes called
``layer of deep syntax''. An example of a tectogrammatical tree can be seen on
the Fig.~\ref{img:tree}. Annotation of a sentence at this layer
is closer to the meaning of the sentence than its syntactic
annotation and thus information captured at the tectogrammatical
layer is crucial for machine understanding
of natural language \citep{dedek:KlTransformationBasedTectogrammatical2006}.
\end{description}


\subsection{Web Information Extraction}

After the content of a web resource is analyzed by the above mentioned linguistic tools, the output linguistic data is stored in the form of tectogrammatical trees. To achieve our objectives we have to extract information from this representation. 
Here we refer to our previous work \citep{dedek:DeVoComputingaggregations2008,dedek:DeVoLinguisticextraction2008,dedek:DeEcExperimentswith2008}. A long path of tools starting with web crawling and resulting with the extracted structured information has been developed in our previous works. 
In the Fig.~\ref{img:tree} nodes of the tectogrammatical tree are decorated. A piece of information about the damage of 8000 CZK can be found there (the three nodes on the right). We have used ILP to learn rules, which are able to detect these nodes. 
%In this paper we will concentrate on the usage of such extracted information to be able to classify content. 
The extraction process requires a human assistance when annotating the training data.

Note that our method is general and is not limited to Czech and can be used with any structured linguistic representation. 


\begin{figure}
\medskip
\centerline{\framebox{\includegraphics[width=0.7\hsize]{img/tree}}}
\caption{Example of a linguistic tree of one of analyzed sentences.}
\label{img:tree}
\end{figure}



To make the paper readable we present a short description of the ILP techniques bellow.

\subsection{Classical ILP}
In our presentation of ILP we follow \cite{dzeroski2001:relat_dm} and  \cite{biblio:Muggleton94inductivelogic}.

%In our application we are facing the challenge of induction and/or mining on several places. First we need an inductive procedure when extracting attributes of an accident from web reports texts. 
%
%Second (the subject of this paper) we need an inductive procedure when trying to explain the degree of seriousness of an accident by the attributes of this accident (the attributes form our background knowledge and we will often refer to them as a background knowledge).
%%
%The places where induction has to be used have following requirements:
%
%
%\begin{itemize}
%	\item the data and the classification is/can be fuzzy,
%	\item in the case of tectogrammatical trees the background knowledge is multirelational.
%\end{itemize}
%
%These requirements and our previous experience with fILP led us to chose the fILP as the machine learning inductive technique in our system. To make the paper readable we present a short description of the ILP techniques bellow.
%%
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}

\begin{definition}[Classical ILP task]
Given is a set of examples $E=P\cup N$, where $P$ contains positive and $N$ negative examples, and background knowledge $B$. The task of ILP is to find a hypothesis $H$ such that 

$$
(\forall e\in P)(B\cup H\models e)
$$
and
$$
(\forall e\in N)(B\cup H\not\models e).
$$
\end{definition}
Typically, $E$ consists of ground instances of the target predicate, in our case accident seriousness (see examples in Fig.~\ref{img:examples}). $B$ typically consists of several predicates (relational tables), which describe properties of an object, in our case properties of an accident (see examples in Fig.~\ref{img:crisp_attributes}). The background knowledge can contain also some rules. A hypothesis $H$ typically consists of logic programming rules (see examples in Fig.~\ref{img:rules}). $H$ added to $B$ entails all positive examples and no negative examples.
%
Main advantage of ILP is its multirelational character, namely $B$ can reside in several relational tables.



\subsection{Fuzzy and GAP induction}

In our presentation of fuzzy ILP we follow the paper of T. Horv\'ath and P. Vojt\'a\v s \citep{biblio:FILP} about fuzzy inductive logic programming.
We use the approach of the fuzzy logic in narrow sense developed by J.~Pavelka \citep{biblio:Pavelka} and P. H\'ajek \citep{biblio:Hajek}. Formulas are of the form $\varphi, x$ ($\varphi$ is syntactically the same as in the classical case), they are graded by a truth value $x\in [0,1]$.
A structure ${\mathcal M}$ consist of a domain $M$ and relations are interpreted fuzzy (we do not consider function symbols here). The evaluation $\left\|\varphi\right\|_{{\mathcal M}}$ of a formula $\varphi$ uses truth functions of many valued connectives (our logic is extensional and/or truth functional). The satisfaction $\models_f$ is defined by
$$
{\mathcal M}\models_f (\varphi, x)\ iff\ \left\|\varphi\right\|_{{\mathcal M}}\ge x.
$$

\begin{definition}[Fuzzy ILP task]
Given are a fuzzy set of examples ${\mathcal E}:E\longrightarrow [0,1]$ and a fuzzy background knowledge ${\mathcal B}:B\longrightarrow [0,1]$. The task of fuzzy ILP is to find a fuzzy hypothesis ${\mathcal H}:H\longrightarrow [0,1]$ such that 

$$
(\forall e_1,e_2\in E)(\forall {\mathcal M})({\mathcal M}\models_f {\mathcal B}\cup {\mathcal H})
$$
we have
$$
{\mathcal E}(e_1)>{\mathcal E}(e_2)\Rightarrow \left\|e_1\right\|_{{\mathcal M}}\ge \left\|e_2\right\|_{{\mathcal M}}.
$$
That is, it cannot happen that
$$
{\mathcal E}(e_1)>{\mathcal E}(e_2) \wedge \left\|e_1\right\|_{{\mathcal M}}< \left\|e_2\right\|_{{\mathcal M}},
$$
or rephrased: if ${\mathcal E}$ is rating $e_1$ higher than $e_2$, then it cannot happen that $e_1$ is rated worse than $e_2$ in a model of ${\mathcal B}\cup {\mathcal H}$.
\end{definition}

Typically, ${\mathcal E}$ consists of ground instances of the target predicate, which are classified in truth degrees -- in our case a degree of seriousness of an accident. ${\mathcal B}$ typically consists of several fuzzy predicates (fuzzy relational tables), which describe properties of an object, in our case fuzzy properties of an accident -- a degree of injury, a degree of damage, etc. 
%Background knowledge can contain also some rules, so far only crisp rules are used.
A~hypothesis ${\mathcal H}$ typically consists of a fuzzy logic program, which, when added to ${\mathcal B}$, prevents of misclassification (better can not be declared to be worse, nevertheless can be declared as having the same degree --- for more detailed discussion on this definition of fuzzy ILP we refer to the paper \citep{biblio:FILP}).

Moreover, in practice, we use GAP -- Generalized Annotated Programs, so graded formulas will be sometimes understood as annotated (with classical connectives and with a more complex annotation of the heads of rules). This is possible, because in \citep{biblio:KLV} we have shown that (some extension of) fuzzy logic programming is equivalent to (some restriction of) generalized annotated programs. 

\subsection{Translation of fuzzy ILP task to several classical ILP tasks}

As far as there is no implementation of fuzzy ILP or GAP, we have to use a~classical ILP system. Fortunately any fuzzy ILP task can be translated to several classical ILP tasks (subject to some rounding and using a finite set of truth values).

In following text assume that all fuzzy sets take truth values only from a finite set of truth values $T: \{0,1\}\subseteq T\subseteq [0,1]$.

\begin{definition}[Transformation of background knowledge]
Given is a fuzzy background knowledge ${\mathcal B}:B\longrightarrow [0,1]$. For each predicate $p(x)$ in $B$ we add an additional attribute $t$ to express the truth value, thus we have created a new predicate $p(x,t)$. We construct two classical background knowledge sets $B^{raw}_T$ and $B^{mon}_T$  as follows:

\begin{itemize}
	\item The first ($B^{raw}_T$) is a direct coding of a fuzzy value by an additional attribute:
\\If ${\mathcal B}(p(x))=t,\  t \in T$, then we add $p(x,t)$ to  ${B}^{raw}_T$.
	\item The second ($B^{mon}_T$) is obtained by a process called monotonization:
\\If ${\mathcal B}(p(x))=t,\  t \in T$, then for all $t'\in T,\  t'\le t$ we add $p(x,t')$ to ${B}^{mon}_T$.
This correspond to natural meaning of truth values $t$.
\end{itemize}
\end{definition}



Also example sets are constructed in two ways.
\begin{definition}[Transformation of examples]
Given is a fuzzy set of examples ${\mathcal E}:E\longrightarrow [0,1]$. For all $t\in T$ we construct two classical sets of examples $E_t$ and $E_{\ge t}$  as follows:
\begin{itemize}
	\item $E_t=P_t\cup N_t$, where 
$e\in P_t \ \ iff \ \ {\mathcal E}(e)= t$
and $N_t$ is the rest of $E$.
	\item $E_{\ge t}=P_{\ge t}\cup N_{\ge t}$, where 
$e\in P_{\ge t} \ \ iff \ \ {\mathcal E}(e)\ge t$
and $N_t$ is the rest of $E$.
\end{itemize}
\end{definition}



These two translations create two classical ILP tasks for each truth value $t\in T$, the first one (\emph{raw}) is crisp and the second one (\emph{mon}) can be understood as (and translated back to) fuzzy ILP.

\begin{itemize}
	\item The \textit{raw ILP task} is given by $B^{raw}_{T}$ and $E_t$ for each $t\in T$.  As a~result it produces a set of hypotheses $H_t$.

	\item The \textit{mon ILP task} is given by ${B}^{mon}_T$ and $E_{\ge t}$ for each $t\in T$. As a~result it produces a set of hypotheses $H_{\ge t}$ guaranteeing examples of a degree of at least $t$.
\end{itemize}

Note that among variable boundings in $B$ there are no boundings on the truth value attribute, which was added to each predicate, and hence there are no variable boundings on the truth value attribute in $H_{\ge t}$. We did not add an additional truth value attribute to the predicates in $E$. 

Now we sketch the translation of the \emph{mon ILP task} to GAP (fuzzy ILP) rules. 

\begin{theorem}[Translation of the \emph{mon ILP task}]
Given is a fuzzy ILP (or equivalent GAP) task given by ${\mathcal E}$ and ${\mathcal B}$. Let us assume that $C$ is the target predicate in the domain of ${\mathcal E}$ and for each $t \in T$ $H_{\ge t}$ is a correctly learned solution of the corresponding \textit{mon ILP task} according to the definitions above. We define ${\mathcal H}$ consisting of one GAP rule:
$$C(y):u(x_1,\dots,x_m)\leftarrow B_1:x_1 \&\dots\& B_m:x_m,$$
here $B_1:x_1 \&\dots\& B_m:x_m$ is the enumeration of all predicates in $B$.

Assume that $B_1(y_1,t_1),\dots,B_n(y_n,t_n)$ are some of the predicates in $B$ (for simplicity enumerated from 1 to $n, \ n \le m$). Then for each rule 
$$R=C(y)\Leftarrow B_1(y_1,t_1),\dots,B_n(y_n,t_n)$$
in $H_{\ge t}$ we give a constraint in definition of $u$ as follows:
$$
U_R=u(x_1,\dots,x_m)\ge t \hbox{ if }x_1\ge t_1,\dots,x_n\ge t_n.
$$
Note that $x_{n+1},\dots,x_m$ have no restrictions.

We claim, that if all $H_{\ge t}$ were correctly learned by a classical ILP system then for the minimal solution $u$ of all constraints $U_R$ the rule
$$
C(y):u(x_1,\dots,x_m)\leftarrow B_1:x_1 \&\dots\& B_n:x_m
$$
is a correct solution of the fuzzy ILP task given by ${\mathcal E}$ and ${\mathcal B}$, for all $R\in H_t$ and $t\in T$. 
\end{theorem}
Our presentation is here a little bit simplified and we freely switch between fuzzy and GAP programs, which are known to be equivalent, see in~\citep{biblio:KLV}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The system prototype and our experiment} \label{sec:prototype_and_experiment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The main experiment presented in this paper leads to the seriousness classification of an accident presented on a web report, %Our long term goal is extraction of semantic information from web reports. 
which is one of possible utilizations of the extracted information. We use web reports of fire departments of several regions of the Czech Republic. These reports are written Czech and can be accessed through the web of the General Directorate of the Fire and Rescue Service of the Czech Republic\footnote{\url{http://www.hzscr.cz}}. 
%These reports are rich in information, e.g. where and when an traffic accident occurred, which units helped, how much time it took them to show up on the place of accident, how many people were injured, killed etc.

For our experiment we have selected a collection of 50 web reports. We have identified several features presented in these reports and manually extracted corresponding values. This will be described in more detail in the section \ref{sec:features}. To each report we have also assigned a value of overall ranking of seriousness of the presented accident, which is the target of the classification. The whole dataset can be downloaded from our Fuzzy ILP classifier's web page\footnote{\url{http://www.ksi.mff.cuni.cz/~dedek/fuzzyILP/}}.

In this experiment we have not used an information extracted by our automated information extraction tools. In this paper we are concentrated on~the classification and the actual source of the information is not so important. The integration step is still waiting to be done.

%There are two objectives to do. Fist is the web information extraction, a long path starting with web crawling and resulting with the extracted structured information. Second is the seriousness classification, which utilizes the extracted information. We have made much work on the first (see e.g. %\citep{biblio:DeVoLinguisticextraction2008,biblio:DeVoComputingaggregations2008, biblio:DeEcExperimentswith2008}), in this paper we will concentrate on the second.
%\citep{biblio:DeEcExperimentswith2008}), in this paper we will concentrate on the second.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment description} \label{sec:experiment_desc}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For the seriousness classification we have used two inductive logic approaches -- Crisp ILP and Fuzzy ILP (as described above). Technically the difference between the approaches consists in different setting of the \emph{ILP task}. Both can be done with a classical ILP tool. We have used 
``\emph{A Learning Engine for Proposing Hypotheses}'' (Aleph  v5\footnote{\url{http://www.comlab.ox.ac.uk/activities/machinelearning/Aleph/}}), which we consider very practical. It uses quite effective method of \emph{inverse entailment} \citep{biblio:InverseEntailment} and keeps all handy features of a Prolog system (it is supported by YAP and SWI Prolog) in its background.

We have compared results of the Crisp and Fuzzy ILP approaches with other classification methods and in our experiment the fuzzy approach made better results than the crisp one and also than many other methods. See the section \ref{sec:results} for the details.



\begin{table}
\centerline{\includegraphics[width=.5\hsize]{img/attributes_description}}
\caption{Accident attributes.}
\label{img:attributes_description}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Features of accidents} \label{sec:features}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\begin{wraptable}{r}{.5\hsize}
%\centerline{\includegraphics[width=\hsize]{img/attributes_description}}
%\caption{Accident attributes.}
%\label{img:attributes_description}
%\end{wraptable}

The table~\ref{img:attributes_description} summarizes all features (or attributes) that we have obtained from accident reports. Except the attribute \verb+type+ (type of an accident -- \verb+fire+, \verb+car_accident+ and \verb+other+) all the attributes are numerical and so monotonizable. There are cases when the value of an attribute is unknown. We have decided to make evidence of this and keep the values \verb+unknown+ in our knowledge base. A brief explanation of each attribute follows.
\begin{itemize}
	\item \verb+size+ is the file size of the text of the particular report.
	\item \verb+damage+ is the amount (in CZK -- Czech Crowns) of the summarized damage arisen during the reported accident.
	\item \verb+dur_minutes+ is the time taken to handle the accident.
	\item \verb+fatalities+ and \verb+injuries+ are the numbers of fatalities and injuries taken by the accident.
	\item \verb+cars+ is the number of cars damaged during the accident (important during car accidents).
	\item \verb+professional_units+ and \verb+amateur_units+ are the numbers of the fireman units sent for the accident.
	\item \verb+pipes+ is the number of used fire pipes.
	\item \verb+lather+, \verb+aqualung+ and \verb+fan+ (ventilator) indicates whether these devices were used.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Seriousness ranking} \label{sec:seriousness}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\vspace{0.2cm}
%\noindent \textbf{Seriousness ranking}

\begin{figure}
\centerline{\includegraphics[width=0.7\hsize]{img/ranking_histogram}}
\caption{Frequencies of the seriousness ranking.}
\label{img:ranking_histogram}
\end{figure}

Values of the overall seriousness ranking attribute were stated from ``a general impression'' from texts of the reports texts with respect to particular attributes. %(Fig.~\ref{img:attributes_description}). 
The values have evolved to 14 distinct values in the range from 0.5 to 8. 
A histogram with frequencies of all the values is on the Figure~\ref{img:ranking_histogram}.
We have divided the values into four approximately equipotent groups 
(see in the Fig.~\ref{img:ranking_histogram}) 
and these groups determine the target class attribute in our classification task. 
%and logic rules were learned for each group separately\footnote{We do not have a binary rule, which would return an exact value of the rating, but we have one ``true/false'' rule for each of the four categories.}.



\begin{figure}[htb]
\begin{minipage}[b]{0.5\hsize}
	Crisp learning examples\\
	\centerline{\includegraphics[width=\hsize]{img/examples_nonmonot}}
	Monotonized learning examples\\
	\centerline{\includegraphics[width=\hsize]{img/examples_monot}}
	\caption{Learning examples.}
	\label{img:examples}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}[b]{0.5\hsize}
	\centerline{\includegraphics[width=0.835\hsize]{img/crisp_attributes}}
	\caption{$B^{raw}_{T}$ -- crisp attributes.}
	\label{img:crisp_attributes}
\end{minipage}
\end{figure}

\begin{figure}[htb]	
	\centerline{\includegraphics[width=0.53\hsize]{img/attribute_monotonisation}}
	\caption{Monotonization of attributes (damage\_atl $\leftarrow$ damage).}
	\label{img:attribute_monotonization}
\end{figure}

\begin{figure}[htb]	
\centerline{\includegraphics[width=0.52\hsize]{img/conversion}}
\caption{Conversion rules for monotonized hypotheses (\texttt{serious\_t} $\leftarrow$ \texttt{serious\_atl\_t}).}
\label{img:conversion}
\end{figure}


%
%\begin{figure}[t!]
%Crisp learning examples\\
%\centerline{\includegraphics[width=.8\hsize]{img/examples_nonmonot}}
%Monotonized learning examples\\
%\centerline{\includegraphics[width=.8\hsize]{img/examples_monot}}
%\caption{Learning examples.}
%\label{img:examples}
%\end{figure}
%
%\begin{figure}[t!]
%damage $\rightarrow$ damage\_atl\\
%\centerline{\includegraphics[width=.8\hsize]{img/attribute_monotonisation}}
%\caption{Monotonization of attributes.}
%\label{img:attribute_monotonization}
%\vspace{-0.5cm}
%\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data transformation} \label{sec:data_transformation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

To use ILP for the classification task we have to translate the input data to the Prolog-like logic representation. As already described in previous sections, the transformations in the crisp and in the fuzzy case are different. Here we will describe the implementation details of the construction of~the~crisp and fuzzy knowledge bases and example sets.

For the construction of the crisp example set $E_t$ we encode the target (class) predicate as \texttt{serious\_t}. The letter \texttt{t} stands for the actual seriousness degree. We use multiple unary predicates \texttt{serious\_0}, \texttt{serious\_1}, etc., instead of one binary predicate \texttt{serious(ID,Degree)}. These two cases are equivalent and we have decided to use the unary one because it is better for~visual distinction of the multiple ILP tasks.

For the construction of the fuzzy (or monotonized) example set $E_{\ge t}$ we encode the target predicate as \texttt{serious\_atl\_t}, see in the Fig.~\ref{img:examples}.



For the construction of the crisp background knowledge $B^{raw}_{T}$ we use a~simple translation of the data to the  predicates. It is illustrated on the Fig.~\ref{img:crisp_attributes}). 


%\begin{figure}
%\centerline{\includegraphics[width=.8\hsize]{img/examples_nonmonot}}
%\caption{Crisp learning examples.}
%\label{img:examples_nonmonot}
%\end{figure}
%
%\begin{figure}
%\centerline{\includegraphics[width=.9\hsize]{img/examples_monot}}
%\caption{Monotonized learning examples.}
%\label{img:examples_monot}
%\end{figure}
%
For the construction of the monotonized background knowledge $B^{mon}_T$ we reuse the crisp background knowledge and add monotonization rules. An~example of the monotonization rules for a crisp predicate of \texttt{damage} is shown on the Fig.~\ref{img:attribute_monotonization}.
%on predicates \texttt{damage} and \texttt{damage\_atl}.
The first rule deals with \texttt{unknown} values and the second serves for the translation. 

All the negations we use (Fig.~\ref{img:attribute_monotonization} and Fig.~\ref{img:conversion}) are the standard Prolog \emph{negations as failure}.


\begin{figure}[bht]
\centerline{\includegraphics[width=0.6\hsize,height=0.65\hsize]{img/rules}}
\caption{Crisp and monotonized hypotheses.}
\label{img:rules}
\end{figure}


Once we have the learning examples and the background knowledge, we can run the ILP inductive learning procedure and obtain learned rules (a learned hypothesis). According to the kind of the ILP task (crisp or monotonized) we obtain corresponding kind (crisp or monotonized) of rules (see e.g. in the Fig.~\ref{img:rules}). But these rules cannot be used directly to solve the classification task. There are common cases when more then one rule is applicable to a single instance, which is to be classified. So we have to select which one to use. For the monotonized hypothesis we select the maximum from all the possibilities. It is illustrated on the Fig.~\ref{img:conversion}. For the crisp hypothesis there is not such clear criterion, so we simply use the fist applicable rule.


On the other hand in the crisp case there are often many instances, which cannot be classified because there is no applicable rule. (In our experiment there was about 51\%
of unclassified instances, see in the next section.) It could be caused by the lack of training data, but the monotonized case does not suffer from this shortage. We can always select the bottom class and -- what is probably more important -- the set of positive training examples is extended by monotonization. 


%\begin{figure}
%\centerline{\includegraphics[width=\hsize]{img/rules_nonmonot}}
%\caption{Crisp hypothesis.}
%\label{img:rules_nonmonot}
%\end{figure}
%
%\begin{figure}
%\centerline{\includegraphics[width=\hsize]{img/rules_monot}}
%\caption{Monotonized hypothesis.}
%\label{img:rules_monot}
%\end{figure}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results} \label{sec:results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The Fig.~\ref{img:rules} summarizes obtained hypotheses learned from our data: 
\begin{itemize}
	\item a crisp hypothesis learned from $E_t$ and $B^{raw}_{T}$ and
	\item a monotonized hypothesis learned from $E_{\ge t}$ and ${B}^{mon}_T$.
\end{itemize}


In both cases the learning examples and the background knowledge have the origin in the same data (the same accidents). They differ in the form of the ILP task (crisp and monotonized). The crisp hypothesis uses only the crisp predicates, the monotonized hypothesis uses only the monotonized predicates.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Evaluation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[p]
\centerline{\includegraphics[width=\hsize]{img/2x10cross}}
\caption{Evaluation of the methods -- average values.}
\label{img:graph2x10}
\end{figure}


\begin{table}[p]
\scriptsize
{\centering \begin{tabular}{lr@{\hspace{0cm}}c@{\hspace{0cm}}rr@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0.05cm}}cr@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0.05cm}}cr@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0.05cm}}cr@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0.05cm}}cr@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0.05cm}}cr@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0.05cm}}c}
\hline
& \multicolumn{3}{c}{Fuzzy}& \multicolumn{4}{c}{Crisp} & \multicolumn{4}{c}{MultPerc} & \multicolumn{4}{c}{SMO} & \multicolumn{4}{c}{J48} & \multicolumn{4}{c}{JRip} & \multicolumn{4}{c}{LBoost} \\
\hline
Corr	& 0.61 & $\pm$ & .19 & .22 & $\pm$ & .17 & $\bullet$ & .41 & $\pm$ & .19 & $\bullet$ & .36 & $\pm$ & .24 & $\bullet$ & .41 & $\pm$ & .22 & $\bullet$ & .44 & $\pm$ & .17 & $\bullet$ & .59 & $\pm$ & .26 &        \\
Incor	& .39 & $\pm$ & .19 & .27 & $\pm$ & .24 &         	& .59 & $\pm$ & .19 & $\circ$ 	& .64 & $\pm$ & .24 & $\circ$ 	& .59 & $\pm$ & .22 & $\circ$ 	& .56 & $\pm$ & .17 & $\circ$ 	& .41 & $\pm$ & .26 &        \\
Uncl	& .00	& $\pm$ & .00	& .51 & $\pm$ & .29 & $\circ$ 	& .00 & $\pm$ & .00 &         	& .00 & $\pm$ & .00 &         	& .00 & $\pm$ & .00 &         	& .00 & $\pm$ & .00 &         	& .00 & $\pm$ & .00 &        \\
Prec	& .56 & $\pm$ & .24 & .53 & $\pm$ & .37 &         	& .35 & $\pm$ & .20 & $\bullet$ & .33 & $\pm$ & .26 &         	& .39 & $\pm$ & .22 &         	& .34 & $\pm$ & .21 & $\bullet$ & .56 & $\pm$ & .28 &        \\
Rec		& .61 & $\pm$ & .19 & .49 & $\pm$ & .32 &         	& .41 & $\pm$ & .19 & $\bullet$ & .36 & $\pm$ & .24 & $\bullet$ & .41 & $\pm$ & .22 & $\bullet$ & .44 & $\pm$ & .17 & $\bullet$ & .59 & $\pm$ & .26 &        \\
F			& .56 & $\pm$ & .20 & .49 & $\pm$ & .33 &         	& .36 & $\pm$ & .19 & $\bullet$ & .32 & $\pm$ & .24 & $\bullet$ & .39 & $\pm$ & .21 &         	& .36 & $\pm$ & .19 & $\bullet$ & .56 & $\pm$ & .27 &        \\
\hline
\multicolumn{21}{c}{$\circ$, $\bullet$ statistically significant improvement or degradation}\\
\end{tabular} \scriptsize \par}
\scriptsize
\smallskip
Legend:\\
{\centering
\begin{tabular}{p{2cm}@{}p{10.5cm}}\\
Fuzzy \dotfill{}& czsem.ILP.FuzzyILPClassifier '' \\
Crisp \dotfill{} & czsem.ILP.CrispILPClassifier '' \\
MultPerc \dotfill{} & functions.MultilayerPerceptron '-L 0.3 -M 0.2 -N 500 -V 0 -S 0 -E 20 -H a' \\
SMO \dotfill{} & functions.SMO '-C 1.0 -L 0.0010 -P 1.0E-12 -N 0 -V -1 -W 1 -K \textbackslash"functions.supportVector.PolyKernel -C 250007 -E 1.0\textbackslash"' \\
J48 \dotfill{} & trees.J48 '-C 0.25 -M 2' \\
JRip \dotfill{} & rules.JRip '-F 3 -N 2.0 -O 2 -S 1' \\
LBoost \dotfill{} & meta.LogitBoost '-P 100 -F 0 -R 1 -L -1.7976931348623157E308 -H 0.1 -S 1 -I 10 -W trees.DecisionStump' \\
\\
Corr \dotfill{} & Percent correct\\
Inor \dotfill{} & Percent incorrect\\
Uncl \dotfill{} & Percent unclassified\\
Prec \dotfill{} & Weighted avg IR precision\\
Rec \dotfill{} 	& Weighted avg IR recall\\
F \dotfill{} 		& Weighted avg F measure\\
\end{tabular}
}
\caption{Evaluation of the methods in 2 times 10-fold cross validation.}
\label{tab:table2x10}
\end{table}


We have evaluated both ILP methods and compared them with other machine learning procedures used in data mining. To make the comparison clear and easy to perform, we have implemented an interface between the ILP methods and the Weka data mining software\footnote{\url{http://www.cs.waikato.ac.nz/ml/weka/}} \citep{biblio:Weka}. This interface makes it possible to use the ILP methods as an ordinary Weka classifier for any\footnote{For the fuzzy ILP method, there is a requirement on the target (class) attribute: it has to be monotonizable (e.g. numeric).} classification task inside the Weka software. Our implementation is publicly available. The data, source codes and an platform independent installer of the Crisp and Fuzzy ILP classifiers for Weka can be downloaded from our Fuzzy ILP classifier's web page\footnote{\url{http://www.ksi.mff.cuni.cz/~dedek/fuzzyILP/}}. This makes our experiment repeatable according to the
SIGMOD Experimental Repeatability Requirements \citep{biblio:SIGMODrepeatability}.


For our experiment we used the Weka Experimenter and performed an experiment in which the Crisp and Fuzzy ILP classifiers were compared with five additional classifiers:
%Jmenovitì rozhodovací stromy J48 \cite{biblio:J48}, Support vector machine klasifikátor SMO \cite{biblio:SMO} a vícevrstvý perceptron \cite{biblio:bishop-1995}.
\begin{itemize}
	\item Multilayer Perceptron \citep{biblio:bishop-1995},
	\item Support Vector Machine classifier SMO \citep{biblio:SMO},
	\item J48 decision tree \citep{biblio:J48},
	\item JRip rules \citep{weka:JRip} and
	\item Additive logistic regression LogitBoost \citep{biblio:LogitBoost}.
\end{itemize}
We have evaluated all the methods two times by 10-fold cross validation on our data. %(section~\ref{sec:experiment_desc}).
The obtained results (average values) are described by the graph on the Fig.~\ref{img:graph2x10} and in the Table~\ref{tab:table2x10} (with standard deviations and decorated statistically significant values).

There is no clear winner in our experiment. But the Fuzzy ILP classifier proved better results than majority of the methods on our data and the results are statistically significant in many cases. Very good results obtained also the LogitBoost. 

The LogitBoost algorithm is described in the publication of \cite{biblio:LogitBoost}.
The basic idea of the boosting algorithm is to learn several simple models
on reweighted data and combine their opinions to get the resulting
classification.
In our case, the simple models where decision stamps, i.e. decision trees
with only one nonleaf node.
In each iteration, an optimal decision stamp for each target value is
learned. Then, the training dataset is reweighted in a way that
records badly classified by current model are given higher weight in the
next iteration.
A new record is classified as follows: for each target value, predictions
of its decision stamps are summed up.
The target value with the highest vote wins.

We consider boosting as an enhancement of decision trees. A deep decision
tree is too dependent on the randomness in the data. It has a high variance.
Boosting of (tiny) trees fits an additive logistic regression model on them,
i.e. uses a statistically justifiable way of building a collection of tiny
trees. This seems to have low variance and keeps high expressiveness (does
not increase bias dramatically).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% U C I
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{table}
\scriptsize
{\centering \begin{tabular}{l|r@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0.3cm}}r@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0.05cm}}cr@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0.05cm}}l@{\hspace{0cm}}r@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0.05cm}}cr@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0.05cm}}cr@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0.05cm}}cr@{\hspace{0cm}}c@{\hspace{0cm}}r@{\hspace{0cm}}cc@{\hspace{0.25cm}}c@{\hspace{0.15cm}}}
& \multicolumn{3}{c}{Fuzzy}& \multicolumn{4}{c}{Crisp} & \multicolumn{4}{c}{MultPerc} & \multicolumn{4}{c}{SMO} & \multicolumn{4}{c}{J48} & \multicolumn{4}{c}{JRip} & \multicolumn{4}{c}{LBoost} & train & test\\
\hline
car & .39 & $\pm$ & .03 & .36 & $\pm$ & .03 & $\bullet$ & .53 & $\pm$ & .02 & $\circ$ & .57 & $\pm$ & .01 & $\circ$ & .50 & $\pm$ & .02 & $\circ$ & .51 & $\pm$ & .03 & $\circ$ & .54 & $\pm$ & .02 & $\circ$ & 173 & 1554\\
\hline
wine & .44 & $\pm$ & .03 & .42 & $\pm$ & .02 & $\bullet$ & .48 & $\pm$ & .02 & $\circ$ & .46 & $\pm$ & .02 & $\circ$ & .47 & $\pm$ & .02 & $\circ$ & .48 & $\pm$ & .03 & $\circ$ & .52 & $\pm$ & .02 & $\circ$ & 160 & 1439\\
\hline
cmc & .79 & $\pm$ & .02 & .77 & $\pm$ & .03 & $\bullet$ & .89 & $\pm$ & .02 & $\circ$ & .81 & $\pm$ & .01 & $\circ$ & .88 & $\pm$ & .02 & $\circ$ & .82 & $\pm$ & .03 & $\circ$ & .85 & $\pm$ & .02 & $\circ$ & 147 & 1325\\
\hline
tae & .50 & $\pm$ & .12 & .39 & $\pm$ & .11 & $\bullet$ & .59 & $\pm$ & .11 & $\circ$ & .55 & $\pm$ & .12 & $\circ$ & .50 & $\pm$ & .12 &  & .37 & $\pm$ & .11 & $\bullet$ & .55 & $\pm$ & .11 & $\circ$ & 135 & 15\\
\hline
pop & .66 & $\pm$ & .09 & .54 & $\pm$ & .17 & $\bullet$ & .57 & $\pm$ & .13 & $\bullet$ & .70 & $\pm$ & .06 & $\circ$ & .70 & $\pm$ & .07 & $\circ$ & .70 & $\pm$ & .06 & $\circ$ & .66 & $\pm$ & .10 &  & 80 & 9\\
\hline

\multicolumn{23}{c}{$\circ$, $\bullet$ statistically significant improvement or degradation}\\
\end{tabular} \scriptsize \par}
\scriptsize
\smallskip
Legend:\\
{\centering
\begin{tabular}{p{2cm}@{}p{10.5cm}}\\
train \dotfill{} & average number ($\pm$1) of training instances in each run\\
test \dotfill{} & average number ($\pm$1) of testing instances in each run\\
\\
car \dotfill{} & \url{http://archive.ics.uci.edu/ml/datasets/Car+Evaluation}\\
wine \dotfill{} & red wine dataset \url{http://archive.ics.uci.edu/ml/datasets/Wine+Quality}\\
cmc \dotfill{} & \url{http://archive.ics.uci.edu/ml/datasets/Contraceptive+Method+Choice}\\
tae \dotfill{} & \url{http://archive.ics.uci.edu/ml/datasets/Teaching+Assistant+Evaluation}\\
pop \dotfill{} & \url{http://archive.ics.uci.edu/ml/datasets/Post-Operative+Patient}\\
\end{tabular}
}

\smallskip

Learning parameters for both ILP methods:\\set(noise,20). set(i,3). set(clauselength,13). set(search,heuristic). set(evalfn,wracc). set(samplesize,3).
\caption{Evaluation of the methods in 2 times 10-fold cross validation.}
\label{tab:UCItable}
\end{table}


\begin{figure}
\centerline{\includegraphics[width=\hsize]{img/corect_growing_learninig_instances}}
\caption{Number of correctly classified instances - number of learning examples.}
\label{img:corect_growing_learninig_instances}
\end{figure}


\begin{figure}
\centerline{\includegraphics[width=\hsize]{img/learning_speed}}
\caption{Learning time - number of learning examples.}
\label{img:learning_speed}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Results2 - stary clanek} \label{sec:results2}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%The Fig.~\ref{img:evaluation} shows the success of these rules on the test data (not used during learning). We have used standard performance measures\footnote{\url{http://en.wikipedia.org/wiki/Precision_and_recall}} often used in information retrieval. There are also exact numbers of \emph{true positives} TP and \emph{false positives} FP from which the performance measures were computed (with respect to the numbers of all testing examples\footnote{These numbers are written in the Fig.~\ref{img:evaluation} in small frames under each test set label.}).
%
%Naturally monotonized hypotheses $H_{\ge t}$ were tested on monotonized examples $E_{\ge t}$ (double-line frame in the Fig.~\ref{img:rules}) and similarly for the crisp case $H_t, E_t$ (dashed-line frame in the Fig.~\ref{img:rules}).
%%Experiments with $E_t$ and $B^{raw}_{T}$ %Results of experiments with $E_t$ and $B^{raw}_{T}$ 
%%gave following rule set, see Fig.~\ref{img:rules_nonmonot}.
%%Evaluation of learning is depicted in the Fig.~\ref{img:evaluation}.
%%\subsection{Experiments $E_{\ge t}, {B}^{mon}_T$}
%%Evaluation of learning is depicted in the green area of Fig.~\ref{img:evaluation}.
%%\subsection{Evaluation and comparison }
%
%We wanted to compare raw and monotonized learning tasks. As they run on different example sets we had to translate results of one learning (rules with head \texttt{serious\_t}) to results of second learning (rules with head \texttt{serious\_atl\_t}). Logic programming translation rules are depicted on the Fig.~\ref{img:monot2nomon_and_invert}. Here the negation ``\texttt{not(serious\_atl\_3(ID))}'' means a standard Prolog \emph{negation as failure}. 
%
%Then the comparison of both learnings is possible, see the numbers in white areas of Fig.~\ref{img:evaluation}.
%
%
%\begin{figure}[ht]
%\begin{minipage}[b]{0.5\hsize}
%	\centering
%		\includegraphics[width=\hsize]{img/Evaluation}
%\caption{Evaluation results.}
%\label{img:evaluation}
%\end{minipage}
%\hspace{0.5cm}
%\begin{minipage}[b]{0.5\hsize}
%crisp $\rightarrow$ monotone\\
%	{\centering
%		\includegraphics[width=\hsize]{img/nomon2monot}}
%monotone $\rightarrow$ crisp\\
%	{\centering
%		\\\includegraphics[width=\hsize]{img/monot2nomon}}
%\caption{Conversion of results.}
%\label{img:monot2nomon_and_invert}
%\end{minipage}
%\end{figure}
%
%
%%\begin{figure}
%%\centerline{\includegraphics[width=0.8\hsize]{img/Evaluation}}
%%\caption{Evaluation results.}
%%\label{img:evaluation}
%%\end{figure}
%%
%%
%%\begin{figure}
%%crisp $\rightarrow$ monotone\\
%%\centerline{\includegraphics[width=.8\hsize]{img/nomon2monot}}
%%
%%monotone $\rightarrow$ crisp\\
%%\centerline{\includegraphics[width=.8\hsize]{img/monot2nomon}}
%%\caption{Conversion of results.}
%%\label{img:monot2nomon_and_invert}
%%\end{figure}
%
%%\begin{figure}
%%\centerline{\includegraphics[width=.8\hsize]{img/nomon2monot}}
%%\caption{Results conv.: crisp $\rightarrow$ monotone.}
%%\label{img:nomon2monot}
%%\end{figure}
%%
%%
%%
%%
%%\begin{figure}
%%\centerline{\includegraphics[width=.8\hsize]{img/monot2nomon}}
%%\caption{Results conv.: monotone $\rightarrow$ crisp.}
%%\label{img:monot2nomon}
%%\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion} \label{sec:conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this paper we have presented a fuzzy system, which provides a fuzzy classification of textual web reports. Our approach is based on usage of third party linguistic analyzers, our previous work on web information extraction and fuzzy inductive logic programming.

Main contributions are formal models, prototype implementation of the presented methods and an evaluation experiment. Our data and our implementation is publicly available on the Web. The experiment has shown the performance of the presented methods and compared them with other machine learning procedures used in data mining. The Fuzzy ILP classifier proved better results than majority of the methods on our data. The results are statistically significant in many cases. 
We see the advantage of the Fuzzy ILP classifier in the fact that monotonization leads to the extension of the learning domain and it utilizes the fact that the domain is or can be monotonically ordered.

We have not performed any additional experiments with other data sets so far because we are primarily interested in our data. This is to be done in the future works and thanks to the public implementation it could be done by anyone interested. 

%Use of ILP was necessary for multirelational character of extracted data (relational representation of XML like form of PDT2.0 tectogramatical trees). 
%
%System need user assistance: of a skilled user in annotating data for extraction and an unskilled user for classification of a small training example set. This feature is especially important, because in Internet application, we cannot expect an unskilled user to classify a big number of examples 

\section*{Acknowledgments}
This work was partially supported by Czech projects: GACR P202/10/0761, GACR-201/09/H057, GAUK 31009 and MSM-0021620838.

\section*{References}

\bibliographystyle{elsarticle-harv}
\bibliography{DedVojVom_SAIAW_FuzzyILP}





\end{document}



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
