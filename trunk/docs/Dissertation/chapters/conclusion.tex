\chapter{Conclusion} \label{sec:ch_conclusion}
%\graphicspath{{../img/ch90/}}

This is the last chapter of the thesis. It contains mainly concluding remarks, some additional discussions and an outlook to the future work. First four sections are dedicated to the four main topics of the thesis, followed by common remarks and discussions. 



\section{Manual Design of Extraction Rules}
We have presented the development of our extraction method based on deep language parsing from its early beginning. Its evolution begun with procedurally written extraction rules (Section~\ref{sec:manual_Procedural_Extraction_Rules}) followed by declarative ones (Section~\ref{sec:manual_Netgraph_Based_Extraction_Rules_method}) and, finally, it was supported by the automated induction of extraction rules using the machine learning technique of Inductive Logic Programming (Section~\ref{sec:learning_methods}).


Our extraction method based on manually designed extraction rules do not consider the annotation aspect of information extraction. Although it is possible to infer an annotation based variety of the presented method, we did not take it into account because during the development of the method the aim was more to produce structured data from text than to produce annotated documents. In the second approach the emphasis was inverted. 

Although the evaluation experiments brought interesting results about different variants of the method (see details in Section~\ref{sec:manual_eval}), a deeper evaluation of the method would be definitely beneficiall, but at the moment, the information provided is the only available. There is no real world application of the method outside the academic ground. The method is still waiting for deep testing and further development in an extensive real world project.



\section{Machine Learning of Extraction Rules}

From our experiments can be seen that ILP is capable to find complex and meaningful rules that cover the intended information. But in terms of the performance measures the results are not better than those from a propositional learner. This is quite surprising observation mainly for Czech because it is a language with free word order and we would expect much better results of the dependency based approach than those of the position based approach, which was used by the propositional learner.

The answer to this issue could be provided by integration of the two approaches: use ILP as a source of good learning features for a propositional learner as described by \cite{DBLP:conf/ilp/RamakrishnanJBS07}. But the usage of ``black box'' propositional learner implies that the extraction model would not be readable and workable for humans any more and its interpretation as extraction ontology by a reasoner would be much more problematic. Further development and experiments with tuning the ILP learning procedure could also bring improvement of the performance but they would require more time, which we decided to invest to other topics of the thesis.

The method is still missing an intelligent semantic interpretation procedure proposed in Section~\ref{sec:learning_SemanticInterpretation} and it could be also evaluated on other datasets (e.g. MUC, ACE, TAC, CoNLL) and other languages. So far we also do not provide a method for classical event and relation extraction. %(like e.g. in \citep{Bunescu:DependencyPaths}). 
In the present solution, we work with events in the same way as with entities; details about this variant of event extraction were provided in Section~\ref{sec:problems_event_entities}. The method has to be adapted for explicit learning of events and relations in the form of ``subject predicate object''.

Our method can also provide a comparison of different linguistic formalisms and tools and their benefit to information extraction (e.g. PDT vs. CoNLL'X vs. Stanford dependencies) because we could run the method using different linguistic analyzers and compare the results on the same dataset.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Shareable Extraction Ontologies} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{From Annotations to Real World Facts} \label{sec:onto_discuss}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In this thesis, we have described our method how to apply an extraction ontology to a document ontology and obtain so called ``annotated'' document ontology. To have an ``annotated'' document ontology is almost the same as to have an annotated document. An annotated document is useful (easier navigation, faster reading and lookup of information, possibility of structured queries on collections of such documents, etc.) but if we are interested in the actual information present in the document, if we want to know the facts that are in a document asserted about the real word things then an annotated document is not sufficient. But the conversion of an annotated document to the real world facts is not simple.
There are obvious issues concerning data integration and duplicity of information. For example when in a document two mentions of people are annotated as `injured', what is then the number of injured people in the corresponding accident? Are the two annotations in fact linked to the same person or not?

In the beginning of our work on the idea of shareable extraction ontologies we planned to develop it further, we wanted to cover also the step from annotated document ontologies to the real world facts. The extraction process would then end up with so called ``fact ontologies''. But two main obstacles prevent us to do that.

\begin{enumerate}
	\item Our IE engine is not yet capable to solve these data integration and duplicity of information issues and the real world facts would be quite imprecise then.
	\item There are also technology problems of creating new facts (individuals) during reasoning.
\end{enumerate}

Because of the decidability and finality constraints of the Description Logic Reasoning it is not possible to create new individuals during the reasoning process. There is no standard way how to do it. But there are some proprietary solutions like \verb@swrlx:createOWLThing@\footnote{\url{http://protege.cim3.net/cgi-bin/wiki.pl?action=browse&id=SWRLExtensionsBuiltIns}} from the Prot\'{e}g\'{e} project and \verb@makeTemp(?x)@ or \verb@makeInstance(?x, ?p, ?v)@\footnote{\url{http://jena.sourceforge.net/inference/#RULEbuiltins}} from the Jena project.
And these solutions can be used in the future work. 

\subsection{How to Obtain a Document Ontology?}

It is true that there are standard means how to obtain a (document) ontology from a document, but these means were not intended for a complex transformation of documents to linguistic structures. Also in our case study (Section~\ref{sec:onto_case}), we did not show how the linguistic preprocessing could be embedded in a GRDDL transformation. In fact, our input documents were already linguistically preprocessed before the GRDDL transformation was performed. We can say that this is just a technical problem but it also illustrates that shareable extraction ontologies and probably also extraction ontologies are still rather a vision, however this vision is realizable today.

\subsection{SPARQL Queries -- Increasing Performance?}

There is also a possibility to transform the extraction rules to SPARQL construct queries. This would probably rapidly increase the time performance. However a document ontology would then have to exactly fit with the schema of the extraction rules.  This would be a minor problem. 

The reason why we did not study this approach from the beginning is that we were interested in extraction \emph{ontologies} and SPARQL queries are not currently regarded as a part of an ontology and nothing is suggesting it to be that way.  

Anyway the performance comparison remains a valuable task for the future work.

\subsection{Contributions for Information Extraction}

Our work on extraction ontologies combines the field of ontology-based information extraction and rule-based reasoning. The aim is to show a new possibility in usage of IE tools and reasoners. The idea of shareable extraction ontologies do not bring a solution that would improve the performance of IE tools.

We also do not provide a proposal of a universal extraction ontology format (although a specific form for the rule based extraction on dependency parsed text could be inferred). This task is left for the future if a need for such activity emerges.
%The aim of the chapter is a demonstration of the idea of tool independent extraction ontologies and the possibility to use reasoners for information extraction.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Summary} \label{sec:onto_conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%In the end of the chapter we would like to summarize the main contributions of the chapter.

%\begin{itemize}
	%\item In the beginning of the chapter we pointed out the draw back of so called extraction ontologies -- in most cases they are dependent on a particular extraction/annotation tool and they cannot be used separately.	
	%\item We extended the concept of extraction ontologies by adding the shareable aspect and we introduced a new principle of making extraction ontologies independent of the original tool: the possibility of application of an extraction ontology to a document by an ordinary reasoner.
	%\item In Section~\ref{sec:onto_case} we presented a case study that shows that the idea of shareable extraction ontologies is realizable. We presented implementation of an IE tool that exports its extraction rules to an extraction ontology and we demonstrated how this extraction ontology can be applied to a document by a reasoner.
	%\item Moreover in Section~\ref{sec:onto_experiment} an experiment with several OWL reasoners was presented. The experiment evaluated the performance of contemporary OWL reasoners on IE tasks (application of extraction ontologies).  
	%\item A new publically available benchmark for OWL reasoning was created together with the experiment. Other reasoners can be tested this way.
%\end{itemize}
   
In the beginning of the description of shareable extraction ontologies, we pointed out the draw back of so called extraction ontologies -- in most cases they are dependent on a particular extraction/annotation tool and they cannot be used separately.	

We extended the concept of extraction ontologies by adding the shareable aspect and we introduced a new principle of making extraction ontologies independent of the original tool: the possibility of application of an extraction ontology to a document by an ordinary reasoner.

In Section~\ref{sec:onto_case} we presented a case study that shows that the idea of shareable extraction ontologies is realizable. We presented implementation of our IE tool that exports its extraction rules to an extraction ontology and we demonstrated how this extraction ontology can be applied to a document by a reasoner.

Moreover in Section~\ref{sec:onto_experiment} an experiment with several OWL reasoners was presented. The experiment evaluated the performance of contemporary OWL reasoners on IE tasks (application of extraction ontologies). A new publically available benchmark for OWL reasoning was created together with the experiment. Other reasoners can be tested this way.

%We would like to conclude the chapter by stating that only time will show if the fundamental idea of the chapter will be useful but today it is at least a new use case for both: usage of IE tools and reasoners.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Fuzzy ILP Classification} \label{sec:conclusion}


In our work on fuzzy ILP classification, we provided a design and partial implementation of a fuzzy system, which provides a fuzzy classification of textual reports. Our approach is based on usage of third party linguistic analyzers, our work on information extraction, and fuzzy inductive logic programming.

The main contributions are formal models, prototype implementation of the presented methods and evaluation experiments. The first experiment evaluated performance of the presented methods and compared them with other machine learning procedures used in data mining on our dataset. The Fuzzy ILP Classifier proved better results than a majority of the methods. The results are statistically significant in many cases. 
We see the advantage of the Fuzzy ILP classifier in the fact that monotonization leads to the extension of the learning domain and it utilizes the fact that the domain is or can be monotonically ordered.

In the second experiment, we evaluated all the methods on other datasets with more training instances and we also experimentally measured the time complexity of the methods. This experiment shows that the fuzzy method is suitable mainly in situations with a small amount of training instances and in cases when the target attribute mostly respects the natural order of the remaining attributes. But this did not hold true for any of the later-used datasets. When comparing the fuzzy approach with the crisp one, the fuzzy approach always performed better in terms of correctness of the classification, but it was many times slower than all the methods in terms of time complexity.



\section{Statistical Significance} \label{sec:conclusion_statsig}
The term statistical significance used in this thesis refers to the result of a pair-wise comparison of learning engines using the corrected resampled (two tailed) T-Test \citep{Nadeau:2003:IGE:779909.779927}, which is suitable for cross validation based experiments. The Weka implementation was used (see some details in Section~\ref{sec:third_weka}). Test significance was 0.05 in all cases.




\section{How to Download} \label{sec:download_notes}
The project website\footnote{\url{http://czsem.berlios.de}} provides several ways how to get all the presented tools running. A platform independent installer, Java binaries and source codes are provided under the GPL license.

Also majority of the datasets mentioned in this thesis are available for public download.

Table~\ref{tab:download_links} provides links to individual resources.


\begin{table}[b!]
\centering
\begin{tabular}{|p{.97\textwidth}|}
		\hline
		Czsem Mining Suite installation: \hfill{} \smallurl{http://czsem.berlios.de/czsem_install.html}\\
		\hline
		Fuzzy ILP Classifier for Weka:  \hfill{} \smallurl{http://www.ksi.mff.cuni.cz/~dedek/fuzzyILP/}\\
		\hline
		Ontologies: \hfill{}\\
		$\,$\hfill{} \smallurl{http://czsem.berlios.de/ontologies/acquisitions-v1.1/download_instructions.html}\\
		$\,$\hfill{} \smallurl{http://czsem.berlios.de/ontologies/czech_fireman/download_instructions.html}\\
		\hline		
		General download area: \hfill{}\\
		$\,$\hfill{} \smallurl{http://developer.berlios.de/project/filelist.php?group_id=8427}\\
		\hline
		Apache Maven repository: \hfill{} \smallurl{http://czsem.berlios.de/maven2/}\\
		\hline 
\end{tabular}
	\caption{Download links to the implementation and datasets.} \label{tab:download_links}
\end{table}

\section{Repeatability of Experiments} \label{sec:conclusion_repeatablity}

Our implementation and datasets are publicly available. This makes our experiments repeatable according to the
SIGMOD Experimental Repeatability Requirements \citep{biblio:SIGMODrepeatability}. If you have any problems concerning the reconstruction of any of the experiments please contact the authors, they will be pleased by providing an assistance. 



\section{Summary}

Our experiments deal with texts in the Czech language but our method is general and it can be used with any structured linguistic representation. 

Let us conclude the whole work by reminding the main contributions mentioned in Section~\ref{sec:phd_contributions}.
